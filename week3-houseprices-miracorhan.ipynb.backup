{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5407,
          "databundleVersionId": 868283,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31259,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Merhaba! AI Engineering Week 3 - House Prices Ã¶dev dosyasÄ±nÄ± ve proje gereksinimlerini detaylÄ±ca inceledim.\n\nBu proje, Kaggle'Ä±n efsanevi baÅŸlangÄ±Ã§ yarÄ±ÅŸmasÄ± olan \"House Prices: Advanced Regression Techniques\" Ã¼zerine kurgulanmÄ±ÅŸ, ancak sadece yÃ¼ksek skor almayÄ± deÄŸil, uÃ§tan uca profesyonel bir makine Ã¶ÄŸrenmesi boru hattÄ± (pipeline) kurmayÄ± hedefleyen kapsamlÄ± bir Ã§alÄ±ÅŸma.\n\nÄ°ÅŸte projenin genel yapÄ±sÄ± ve dikkat etmemiz gereken kritik noktalar hakkÄ±nda Ã¶zet bilgiler:\n\nğŸ“‹ Proje Genel BakÄ±ÅŸÄ±\nBu Ã¶devde amaÃ§, Ames, Iowa'daki evlerin Ã¶zelliklerini (79 farklÄ± deÄŸiÅŸken) kullanarak satÄ±ÅŸ fiyatlarÄ±nÄ± (SalePrice) tahmin etmektir. Ancak Ã¶devin asÄ±l odak noktasÄ± model baÅŸarÄ±sÄ±ndan ziyade sÃ¼reÃ§ yÃ¶netimidir.\n\nğŸ”‘ Kritik Noktalar ve Strateji\nVeri Ã‡eÅŸitliliÄŸi: Veri setinde sayÄ±sal (Metrekare, Oda sayÄ±sÄ± vb.) ve kategorik (Mahalle, Kaplama tipi vb.) Ã§ok fazla deÄŸiÅŸken var. Bu yÃ¼zden BÃ¶lÃ¼m E (Preprocessing Pipeline) ve BÃ¶lÃ¼m C (Data Cleaning) aÅŸamalarÄ± projenin kalbi olacak.\n\nHedef DeÄŸiÅŸken (SalePrice): Ã–dev, fiyatlarÄ±n daÄŸÄ±lÄ±mÄ±nÄ± dÃ¼zeltmek iÃ§in Logaritmik dÃ¶nÃ¼ÅŸÃ¼m (log1p) yapmamÄ±zÄ± Ã¶neriyor. Bu, Ã¶zellikle Kaggle'Ä±n deÄŸerlendirme metriÄŸi olan RMSLE (Root Mean Squared Logarithmic Error) ile uyumludur.\n\nÃ–zellik MÃ¼hendisliÄŸi (Feature Engineering): Var olan verilerden en az 5 yeni anlamlÄ± Ã¶zellik tÃ¼retmemiz isteniyor (Ã–rn: Evin yaÅŸÄ±, toplam banyo sayÄ±sÄ±). Bu adÄ±m model performansÄ±nÄ± en Ã§ok artÄ±ran adÄ±mdÄ±r.\n\nModel AÃ§Ä±klanabilirliÄŸi (SHAP): Sadece \"Ev 500.000$ eder\" demek yetmiyor; SHAP kÃ¼tÃ¼phanesini kullanarak \"Neden bu fiyat?\" sorusuna cevap vermemiz (Ã–rn: \"Mutfak kalitesi fiyatÄ± 20.000$ artÄ±rdÄ±\") isteniyor.\n\nHata Analizi: Modelin en Ã§ok yanÄ±ldÄ±ÄŸÄ± 3 evi inceleyip \"Nerede hata yaptÄ±k?\" sorusunu sormamÄ±z bekleniyor. Bu, gerÃ§ek dÃ¼nyadaki AI mÃ¼hendisliÄŸi pratiÄŸinin Ã¶nemli bir parÃ§asÄ±dÄ±r.\n\nğŸš€ Kaggle OrtamÄ± Ä°Ã§in HazÄ±rlÄ±k\nKaggle Notebook Ã¼zerinde Ã§alÄ±ÅŸacaÄŸÄ±mÄ±z iÃ§in veri setleri otomatik olarak ../input/house-prices-advanced-regression-techniques/ dizininde bulunacaktÄ±r. KÃ¼tÃ¼phane kurulumlarÄ± (Pandas, Scikit-learn, SHAP vb.) Kaggle ortamÄ±nda hazÄ±rdÄ±r, gerekirse eksikleri yÃ¼kleyebiliriz.\n\nYÃ¶nergenize uygun olarak sÄ±ra sÄ±ra ilerlemeye hazÄ±rÄ±m.\n\n\"BaÅŸla\" dediÄŸinizde veya A ÅÄ±kkÄ± (Data Loading) ile ilgili komutu verdiÄŸinizde kodlamaya baÅŸlayabiliriz.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Harika, ilk adÄ±mla baÅŸlÄ±yoruz. Kaggle Notebook Ã¼zerinde Ã§alÄ±ÅŸacaÄŸÄ±n iÃ§in veri yollarÄ±nÄ± Kaggle'Ä±n standart dosya sistemine gÃ¶re ayarladÄ±m.\n\nâœ… A) Veri YÃ¼kleme ve Ä°nceleme (Data Loading and Inspection)\nAÅŸaÄŸÄ±daki kod bloÄŸu ile verileri yÃ¼kleyip genel yapÄ±sÄ±nÄ± analiz edebilirsin:",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "ğŸ’¡ Bu AdÄ±mda Dikkat Ã‡ekenler\nTarget (Hedef): SalePrice sÃ¼tunu sadece train setinde bulunur, test setinde bulunmaz.\n\nId SÃ¼tunu: Her iki sette de bulunan Id sÃ¼tunu bir Ã¶zellik (feature) deÄŸil, benzersiz bir belirleyicidir. Analiz sÄ±rasÄ±nda bunu dikkate almalÄ±yÄ±z.\n\nVeri Tipleri: float64, int64 (sayÄ±sal) ve object (kategorik) verilerin karÄ±ÅŸÄ±k olduÄŸunu gÃ¶receksin.\n\nBu adÄ±mÄ± Kaggle notebook'unda Ã§alÄ±ÅŸtÄ±rdÄ±ktan sonra Ã§Ä±ktÄ±larÄ± inceleyebilirsin. HazÄ±r olduÄŸunda bir sonraki aÅŸama olan B) EDA (Exploratory Data Analysis) adÄ±mÄ±na geÃ§ebiliriz.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport os\n\n# ğŸŒ Ortam Tespiti (Kaggle vs Local)\nif os.path.exists('/kaggle/input/house-prices-advanced-regression-techniques'):\n    # Kaggle ortamÄ±\n    data_dir = '/kaggle/input/house-prices-advanced-regression-techniques'\n    print(\"ğŸ”µ Kaggle ortamÄ±nda Ã§alÄ±ÅŸÄ±yoruz\")\nelse:\n    # Local ortam - mevcut dizini kullan\n    data_dir = '.'\n    print(\"ğŸŸ¢ Local ortamda Ã§alÄ±ÅŸÄ±yoruz\")\n\nprint(f\"ğŸ“‚ Veri dizini: {data_dir}\")\n\n# 1. Verileri Oku\ntrain_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n\n# 2. BoyutlarÄ± YazdÄ±r (Shape)\nprint(f\"EÄŸitim Seti (Train): {train_df.shape}\")\nprint(f\"Test Seti (Test): {test_df.shape}\")\n\n# 3. Ä°lk 5 satÄ±rÄ± gÃ¶ster (Head)\nprint(\"\\nÄ°lk 5 SatÄ±r:\")\ndisplay(train_df.head())",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:29.858954Z",
          "iopub.execute_input": "2026-01-23T09:51:29.859317Z",
          "iopub.status.idle": "2026-01-23T09:51:29.902460Z",
          "shell.execute_reply.started": "2026-01-23T09:51:29.859294Z",
          "shell.execute_reply": "2026-01-23T09:51:29.901476Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Verilerimiz yÃ¼klendiÄŸine gÃ¶re artÄ±k veriyi anlama ve gÃ¶rselleÅŸtirme aÅŸamasÄ±na geÃ§ebiliriz. Bu aÅŸama, modelimizin neden bazÄ± hatalar yapabileceÄŸini veya hangi Ã¶zelliklerin fiyatÄ± en Ã§ok etkilediÄŸini anlamamÄ±z iÃ§in kritiktir.\n\nâœ… B) EDA (Exploratory Data Analysis)\nAÅŸaÄŸÄ±daki kod bloÄŸu, Ã¶devde belirtilen tÃ¼m gÃ¶rselleÅŸtirmeleri ve analizleri sÄ±rasÄ±yla yapacaktÄ±r:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# GÃ¶rselleÅŸtirme ayarlarÄ±\nsns.set_theme(style=\"whitegrid\")\nplt.figure(figsize=(15, 10))\n\n# --- 1. Hedef DeÄŸiÅŸken Analizi (SalePrice) ---\nfig, axes = plt.subplots(1, 2, figsize=(16, 5))\n\n# SalePrice Histogram\nsns.histplot(train_df['SalePrice'], kde=True, ax=axes[0], color='blue')\naxes[0].set_title('SalePrice DaÄŸÄ±lÄ±mÄ± (Orijinal)')\n\n# Log1p SalePrice Histogram\nsns.histplot(np.log1p(train_df['SalePrice']), kde=True, ax=axes[1], color='green')\naxes[1].set_title('SalePrice DaÄŸÄ±lÄ±mÄ± (Log1p DÃ¶nÃ¼ÅŸÃ¼mÃ¼)')\nplt.show()\n\n# --- 2. Eksik DeÄŸer Analizi ---\nmissing = train_df.isnull().sum()\nmissing = missing[missing > 0].sort_values(ascending=False)\nmissing_perc = (missing / len(train_df)) * 100\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=missing[:20].index, y=missing_perc[:20])\nplt.xticks(rotation=90)\nplt.title('Top 20 Eksik DeÄŸere Sahip SÃ¼tunlar (%)')\nplt.ylabel('Eksik DeÄŸer YÃ¼zdesi')\nplt.show()\n\n# --- 3. Korelasyon Analizi (SayÄ±sal) ---\n# Sadece sayÄ±sal sÃ¼tunlarÄ± seÃ§elim\nnumeric_train = train_df.select_dtypes(include=[np.number])\ntop_corr_features = numeric_train.corr()['SalePrice'].sort_values(ascending=False).head(20).index\n\nplt.figure(figsize=(15, 12))\nsns.heatmap(train_df[top_corr_features].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('SalePrice ile En YÃ¼ksek Korelasyona Sahip 20 Ã–zellik')\nplt.show()\n\n# --- 4. Ã–zellik vs SalePrice GÃ¶rselleÅŸtirmeleri ---\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# OverallQual vs SalePrice\nsns.boxplot(x='OverallQual', y='SalePrice', data=train_df, ax=axes[0, 0])\naxes[0, 0].set_title('Overall Quality vs SalePrice')\n\n# GrLivArea vs SalePrice\nsns.scatterplot(x='GrLivArea', y='SalePrice', data=train_df, ax=axes[0, 1])\naxes[0, 1].set_title('GrLivArea (YaÅŸam AlanÄ±) vs SalePrice')\n\n# YearBuilt vs SalePrice\nsns.scatterplot(x='YearBuilt', y='SalePrice', data=train_df, ax=axes[1, 0])\naxes[1, 0].set_title('Year Built vs SalePrice')\n\n# GarageCars vs SalePrice\nsns.boxplot(x='GarageCars', y='SalePrice', data=train_df, ax=axes[1, 1])\naxes[1, 1].set_title('Garage Cars vs SalePrice')\n\nplt.tight_layout()\nplt.show()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:29.903940Z",
          "iopub.execute_input": "2026-01-23T09:51:29.904251Z",
          "iopub.status.idle": "2026-01-23T09:51:31.888383Z",
          "shell.execute_reply.started": "2026-01-23T09:51:29.904229Z",
          "shell.execute_reply": "2026-01-23T09:51:31.887622Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import skew\n\n# B) EDA BÃ¶lÃ¼mÃ¼ iÃ§in SayÄ±sal Analiz Ã‡Ä±ktÄ±larÄ±\n\nprint(\"--- 1. HEDEF DEÄÄ°ÅKEN (SalePrice) ANALÄ°ZÄ° ---\")\nskew_orig = skew(train_df['SalePrice'])\nskew_log = skew(np.log1p(train_df['SalePrice']))\nprint(f\"Orijinal SalePrice Ã‡arpÄ±klÄ±k (Skewness): {skew_orig:.2f}\")\nprint(f\"Log DÃ¶nÃ¼ÅŸÃ¼mlÃ¼ SalePrice Ã‡arpÄ±klÄ±k (Skewness): {skew_log:.2f}\")\nprint(\"Yorum: 0'a ne kadar yakÄ±nsa o kadar normal daÄŸÄ±lÄ±ma yakÄ±ndÄ±r.\\n\")\n\nprint(\"--- 2. EKSÄ°K DEÄER ANALÄ°ZÄ° (TOP 20) ---\")\nmissing_data = train_df.isnull().sum()\nmissing_data = pd.DataFrame({\n    'Eksik SayÄ±sÄ±': missing_data[missing_data > 0],\n    'YÃ¼zde (%)': (missing_data[missing_data > 0] / len(train_df)) * 100\n}).sort_values(by='Eksik SayÄ±sÄ±', ascending=False).head(20)\nprint(missing_data)\nprint(\"\\n\")\n\nprint(\"--- 3. KORELASYON ANALÄ°ZÄ° (Ä°LK 10 Ã–ZELLÄ°K) ---\")\n# Sadece sayÄ±sal sÃ¼tunlar arasÄ±nda SalePrice ile korelasyon\nnumeric_cols = train_df.select_dtypes(include=[np.number])\ntop_10_corr = numeric_cols.corr()['SalePrice'].sort_values(ascending=False).head(11)\nprint(top_10_corr)\nprint(\"\\n\")\n\nprint(\"--- 4. ZORUNLU GÃ–RSELLEÅTÄ°RME Ã–ZELLÄ°KLERÄ° Ä°STATÄ°STÄ°KLERÄ° ---\")\n\n# OverallQual vs SalePrice OrtalamalarÄ±\nqual_mean = train_df.groupby('OverallQual')['SalePrice'].mean().round(0)\nprint(\"Kalite PuanÄ±na GÃ¶re Ortalama SatÄ±ÅŸ FiyatlarÄ±:\")\nprint(qual_mean)\n\n# GarageCars vs SalePrice OrtalamalarÄ±\ngarage_mean = train_df.groupby('GarageCars')['SalePrice'].mean().round(0)\nprint(\"\\nGaraj AraÃ§ Kapasitesine GÃ¶re Ortalama SatÄ±ÅŸ FiyatlarÄ±:\")\nprint(garage_mean)\n\n# GrLivArea ve YearBuilt KorelasyonlarÄ±\narea_corr = train_df['GrLivArea'].corr(train_df['SalePrice'])\nyear_corr = train_df['YearBuilt'].corr(train_df['SalePrice'])\nprint(f\"\\nYaÅŸam AlanÄ± (GrLivArea) Korelasyonu: {area_corr:.2f}\")\nprint(f\"YapÄ±m YÄ±lÄ± (YearBuilt) Korelasyonu: {year_corr:.2f}\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:31.889342Z",
          "iopub.execute_input": "2026-01-23T09:51:31.889557Z",
          "iopub.status.idle": "2026-01-23T09:51:31.915548Z",
          "shell.execute_reply.started": "2026-01-23T09:51:31.889540Z",
          "shell.execute_reply": "2026-01-23T09:51:31.914463Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "EDA SayÄ±sal SonuÃ§larÄ±nÄ±n Yorumu\n1. Hedef DeÄŸiÅŸken (SalePrice) DÃ¶nÃ¼ÅŸÃ¼mÃ¼\nAnaliz: Orijinal verideki 1.88 olan Ã§arpÄ±klÄ±k (skewness) deÄŸeri, log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ile 0.12'ye dÃ¼ÅŸmÃ¼ÅŸ.\n\nYorum: Bu, yaptÄ±ÄŸÄ±mÄ±z en kritik hamlelerden biri. 1.88 deÄŸeri verinin saÄŸa Ã§ok Ã§arpÄ±k olduÄŸunu ve modelin yÃ¼ksek fiyatlÄ± evleri tahmin ederken zorlanacaÄŸÄ±nÄ± gÃ¶steriyordu. 0.12 deÄŸeri ise verinin artÄ±k neredeyse mÃ¼kemmel bir normal daÄŸÄ±lÄ±ma sahip olduÄŸunu kanÄ±tlÄ±yor. Bu durum, Ridge gibi lineer modellerin hata payÄ±nÄ± minimize eder.\n\n2. Eksik DeÄŸer Analizi\nAnaliz: En Ã§ok eksik veri %17.7 ile LotFrontage (SokaÄŸa bakan cephe) sÃ¼tununda.\n\nYorum: Veri setinin genelinde eksiklik oranÄ± oldukÃ§a dÃ¼ÅŸÃ¼k. %17-18 seviyesindeki eksiklikler model iÃ§in bÃ¼yÃ¼k bir risk teÅŸkil etmez; bunlarÄ± \"median\" (medyan) ile doldurmak verinin genel yapÄ±sÄ±nÄ± bozmayacaktÄ±r. DiÄŸer sÃ¼tunlardaki eksikliklerin %1'in altÄ±nda olmasÄ±, veri kalitesinin yÃ¼ksek olduÄŸunu gÃ¶steriyor.\n\n3. Korelasyon ve Ã–nemli Ã–zellikler\nAnaliz: TotalSF (0.83) ve OverallQual (0.80) en yÃ¼ksek korelasyona sahip Ã¶zellikler.\n\nYorum: * Kendi oluÅŸturduÄŸumuz TotalSF Ã¶zelliÄŸinin, orijinal GrLivArea (0.73) Ã¶zelliÄŸinden daha yÃ¼ksek bir korelasyona (0.83) sahip olmasÄ±, Feature Engineering (Ã–zellik MÃ¼hendisliÄŸi) adÄ±mÄ±mÄ±zÄ±n ne kadar baÅŸarÄ±lÄ± olduÄŸunu kanÄ±tlÄ±yor.\n\nEvin toplam metrekaresi ve genel kalitesi, fiyatÄ± belirleyen en baskÄ±n iki unsurdur.\n\n4. Zorunlu GÃ¶rselleÅŸtirmelerin Derinlemesine Analizi\nOverallQual (Genel Kalite): 1 puandan 10 puana geÃ§iÅŸte ortalama fiyatÄ±n 50.150$'dan 471.865$'a Ã§Ä±ktÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz. Bu, kalitedeki her 1 birimlik artÄ±ÅŸÄ±n fiyata doÄŸrusal deÄŸil, artan bir ivmeyle (logaritmik/Ã¼stel) yansÄ±dÄ±ÄŸÄ±nÄ± gÃ¶sterir.\n\nGarageCars (Garaj Kapasitesi): * Fiyat, 3 araÃ§lÄ±k kapasiteye kadar dÃ¼zenli artÄ±yor (310.330$).\n\nAncak 4 araÃ§lÄ±k garajlarda fiyatÄ±n 192.656$'a dÃ¼ÅŸtÃ¼ÄŸÃ¼ gÃ¶rÃ¼lÃ¼yor.\n\nKritik Yorum: Bu bir \"paradoks\" gibi gÃ¶rÃ¼nse de muhtemelen veri setinde 4 araÃ§lÄ±k garajÄ± olan ev sayÄ±sÄ±nÄ±n Ã§ok az olmasÄ±ndan veya bu evlerin Ã§ok eski/dÃ¼ÅŸÃ¼k kaliteli olmasÄ±ndan kaynaklanÄ±yor. Modelin bu noktada yanÄ±lma ihtimaline karÅŸÄ± dikkatli olunmalÄ±.\n\nYearBuilt (YapÄ±m YÄ±lÄ±): 0.52'lik korelasyon, yeni evlerin genellikle daha pahalÄ± olduÄŸunu ancak metrekare kadar belirleyici olmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor. Yani \"kÃ¼Ã§Ã¼k ve yeni\" bir ev yerine \"bÃ¼yÃ¼k ve eski\" bir ev daha pahalÄ± olabilir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "ğŸ” EDA BulgularÄ± ve Yorumlar (Ã–dev Ä°Ã§in Notlar)\nHedef Analizi: SalePrice orijinal haliyle saÄŸa Ã§arpÄ±k (right-skewed) bir daÄŸÄ±lÄ±m sergiliyor. Logaritmik dÃ¶nÃ¼ÅŸÃ¼m (log1p) sonrasÄ± verinin normal daÄŸÄ±lÄ±ma Ã§ok daha yaklaÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz. Bu, modelin daha kararlÄ± Ã¶ÄŸrenmesini saÄŸlar.\n\nEksik DeÄŸerler: PoolQC, MiscFeature ve Alley gibi sÃ¼tunlarda %90'Ä±n Ã¼zerinde eksik veri var. Bu sÃ¼tunlarÄ± temizlik aÅŸamasÄ±nda dikkatle ele almalÄ±yÄ±z (muhtemelen \"None\" olarak dolduracaÄŸÄ±z).\n\nKorelasyon: OverallQual ve GrLivArea fiyatla en gÃ¼Ã§lÃ¼ pozitif iliÅŸkiye sahip deÄŸiÅŸkenler.\n\nGÃ¶rselleÅŸtirme YorumlarÄ±:\n\nOverallQual vs SalePrice: Malzeme kalitesi arttÄ±kÃ§a fiyatÄ±n logaritmik bir artÄ±ÅŸ eÄŸilimine girdiÄŸi net gÃ¶rÃ¼lÃ¼yor. En yÃ¼ksek kalitede fiyat varyansÄ± (sapmasÄ±) daha yÃ¼ksek.\n\nGrLivArea vs SalePrice: Genel olarak yaÅŸam alanÄ± bÃ¼yÃ¼dÃ¼kÃ§e fiyat artÄ±yor. Ancak saÄŸ alt kÃ¶ÅŸede aykÄ±rÄ± deÄŸerler (outliers) gÃ¶ze Ã§arpÄ±yor (alan Ã§ok bÃ¼yÃ¼k ama fiyat dÃ¼ÅŸÃ¼k).\n\nYearBuilt vs SalePrice: Yeni evler genellikle daha pahalÄ±, ancak Ã§ok eski (tarihi) evlerin de bazen yÃ¼ksek fiyatlara satÄ±labildiÄŸi gÃ¶rÃ¼lÃ¼yor.\n\nGarageCars vs SalePrice: 3 araÃ§lÄ±k garajÄ± olan evler en yÃ¼ksek ortalama fiyata sahip. Ä°lginÃ§ bir ÅŸekilde 4 araÃ§lÄ±k garajlarda fiyat dÃ¼ÅŸÃ¼ÅŸÃ¼ var, bu verideki az sayÄ±daki Ã¶rnekten kaynaklanabilir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "âœ… C) Data Cleaning (MANDATORY)\n1. Filling Missing Values\n\nNumerical columns: Use median.\nCategorical columns: Use most_frequent or \"None\".\nNote: In some columns like GarageType, \"None\" might be a meaningful category.\n2. Outlier Handling (MANDATORY) Apply at least one outlier method.\n\nExample: Identify and remove rows where GrLivArea is very high but SalePrice is low, or apply capping to extreme values.\nGoal: Reduce incorrect learning for the model.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Veri temizleme aÅŸamasÄ±, modelin gÃ¼rÃ¼ltÃ¼lÃ¼ veriden (noise) etkilenmemesi ve eksik bilgiler yÃ¼zÃ¼nden hata vermemesi iÃ§in en kritik adÄ±mlardan biridir. Bu aÅŸamada Ã¶zellikle gÃ¶rselleÅŸtirmelerde fark ettiÄŸimiz aykÄ±rÄ± deÄŸerleri (outliers) temizleyeceÄŸiz.\n\nâœ… C) Veri Temizleme (Data Cleaning)\nBu kod bloÄŸunda Ã¶nce aykÄ±rÄ± deÄŸerleri silecek, ardÄ±ndan eksik deÄŸerleri nasÄ±l dolduracaÄŸÄ±mÄ±zÄ± belirleyeceÄŸiz.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# --- 1. AykÄ±rÄ± DeÄŸerlerin Temizlenmesi (Outlier Handling) ---\n# GrLivArea vs SalePrice grafiÄŸinde saÄŸ altta gÃ¶rÃ¼nen (alanÄ± Ã§ok bÃ¼yÃ¼k ama fiyatÄ± Ã§ok dÃ¼ÅŸÃ¼k) \n# noktalar modelin kafasÄ±nÄ± karÄ±ÅŸtÄ±rÄ±r. BunlarÄ± temizleyelim.\n\nplt.figure(figsize=(8, 5))\nsns.scatterplot(x='GrLivArea', y='SalePrice', data=train_df)\nplt.title('Temizlik Ã–ncesi: GrLivArea vs SalePrice')\nplt.show()\n\n# GrLivArea 4000'den bÃ¼yÃ¼k olup SalePrice'Ä± 300.000'den dÃ¼ÅŸÃ¼k olanlarÄ± Ã§Ä±karalÄ±m\noutliers = train_df[(train_df['GrLivArea'] > 4000) & (train_df['SalePrice'] < 300000)].index\ntrain_df = train_df.drop(outliers).reset_index(drop=True)\n\nprint(f\"{len(outliers)} adet aykÄ±rÄ± deÄŸer silindi.\")\n\n# --- 2. Eksik DeÄŸer Stratejisi ---\n# Not: GerÃ§ek doldurma iÅŸlemini Pipeline iÃ§inde 'SimpleImputer' ile yapacaÄŸÄ±z.\n# Ancak bazÄ± sÃ¼tunlarda NaN aslÄ±nda \"Yok\" (None) demektir. \n\n# Kategorik olup NaN deÄŸerinin \"Yok\" anlamÄ±na geldiÄŸi sÃ¼tunlar:\ncat_none_cols = [\n    'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', \n    'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n    'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType'\n]\n\n# Bu sÃ¼tunlardaki NaN deÄŸerlerini \"None\" ile dolduralÄ±m\nfor col in cat_none_cols:\n    train_df[col] = train_df[col].fillna(\"None\")\n    test_df[col] = test_df[col].fillna(\"None\")\n\n# Geri kalan sayÄ±sal sÃ¼tunlar medyan ile, \n# geri kalan kategorik sÃ¼tunlar en Ã§ok tekrar eden (most_frequent) ile Pipeline'da dolacak.",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:31.917411Z",
          "iopub.execute_input": "2026-01-23T09:51:31.917667Z",
          "iopub.status.idle": "2026-01-23T09:51:32.063514Z",
          "shell.execute_reply.started": "2026-01-23T09:51:31.917640Z",
          "shell.execute_reply": "2026-01-23T09:51:32.062473Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "ğŸ› ï¸ YapÄ±lan Ä°ÅŸlemlerin AÃ§Ä±klamasÄ±\n1. AykÄ±rÄ± DeÄŸerler (Outliers)\nNeden: GrLivArea (YaÅŸam alanÄ±) 4000 fit kareden bÃ¼yÃ¼k olan evler genellikle Ã§ok pahalÄ±dÄ±r. Ancak veri setinde Ã§ok bÃ¼yÃ¼k olup Ã§ok ucuza satÄ±lmÄ±ÅŸ birkaÃ§ ev var. Bunlar \"tarÄ±m arazisi\" veya \"Ã¶zel durumlu satÄ±ÅŸ\" olabilir. Modelin bu uÃ§ Ã¶rnekleri genel kural sanmasÄ±nÄ± engellemek iÃ§in onlarÄ± Ã§Ä±kardÄ±k.\n\n2. Eksik DeÄŸer Doldurma (Imputation)\nSayÄ±sal SÃ¼tunlar: median (medyan) kullanacaÄŸÄ±z. Ortalama (mean) yerine medyanÄ± seÃ§memizin sebebi, medyanÄ±n uÃ§ deÄŸerlere karÅŸÄ± daha dayanÄ±klÄ± olmasÄ±dÄ±r.\n\nKategorik SÃ¼tunlar: * \"None\" Stratejisi: BazÄ± Ã¶zellikler (Havuz, Ã‡it, Garaj) her evde bulunmaz. Veri setinde bu sÃ¼tunlarÄ±n boÅŸ olmasÄ± \"Havuz Yok\" demektir. Bu yÃ¼zden bunlarÄ± \"None\" kelimesiyle doldurduk.\n\n\"Most Frequent\" Stratejisi: Elektrik sistemi gibi her evde olmasÄ± gereken ama verisi girilmemiÅŸ yerleri en yaygÄ±n deÄŸerle dolduracaÄŸÄ±z (Bu adÄ±m Pipeline'da gerÃ§ekleÅŸecek).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "SÃ¼tunlarÄ± analiz etmek ve hangilerinin modele katkÄ± saÄŸlamayacaÄŸÄ±nÄ± (gÃ¼rÃ¼ltÃ¼ oluÅŸturacaÄŸÄ±nÄ±) belirlemek, modelin daha sade ve etkili Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar. Ã–zellikle \"Constant\" (sabit) veya \"Near-Constant\" (neredeyse sabit) Ã¶zellikler ile \"ID\" gibi benzersiz belirleyiciler temizlenmelidir.\n\nAÅŸaÄŸÄ±daki kod bloÄŸunu Kaggle notebook'unda Ã§alÄ±ÅŸtÄ±rÄ±p sonuÃ§larÄ± bana verirsen, hangi sÃ¼tunlarÄ± kesin olarak silebileceÄŸimizi teyit edebiliriz.\n\nğŸ Analiz Ä°Ã§in Python Kodu\nBu kod, verideki Ã§eÅŸitliliÄŸi (variance) ve baskÄ±n deÄŸerleri kontrol eder:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\n# 1. Benzersiz DeÄŸer Analizi (Hangi sÃ¼tun hep aynÄ± deÄŸerden oluÅŸuyor?)\ndef analyze_unnecessary_columns(df):\n    stats = []\n    for col in df.columns:\n        # En Ã§ok tekrar eden deÄŸerin oranÄ±\n        most_freq_value_counts = df[col].value_counts(normalize=True).iloc[0]\n        # Benzersiz deÄŸer sayÄ±sÄ±\n        unique_values = df[col].nunique()\n        \n        stats.append({\n            'Column': col,\n            'Most_Freq_Val_Share': most_freq_value_counts,\n            'Unique_Values': unique_values\n        })\n    \n    return pd.DataFrame(stats).sort_values(by='Most_Freq_Val_Share', ascending=False)\n\nanalysis_df = analyze_unnecessary_columns(train_df)\nprint(analysis_df[analysis_df['Most_Freq_Val_Share'] > 0.95]) # %95'i aynÄ± olan sÃ¼tunlar",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.064400Z",
          "iopub.execute_input": "2026-01-23T09:51:32.064619Z",
          "iopub.status.idle": "2026-01-23T09:51:32.108700Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.064599Z",
          "shell.execute_reply": "2026-01-23T09:51:32.107975Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Id\tSadece bir kayÄ±t numarasÄ±dÄ±r; evin fiyatÄ± Ã¼zerinde yapÄ±sal bir etkisi yoktur.\n\nUtilities, Street, Heating\t%98-%99 oranÄ±nda aynÄ± deÄŸere sahipler. Model iÃ§in hiÃ§bir ayÄ±rt edici bilgi taÅŸÄ±mazlar.\n\nPoolArea, PoolQC\tEvlerin %99.5'inde havuz yok. Bu kadar az veri modeli genelleme yapmak yerine ezberlemeye (overfitting) iter.\n\nCondition2, RoofMatl\tVerilerin neredeyse tamamÄ± tek bir tipte toplanmÄ±ÅŸ, varyans (deÄŸiÅŸkenlik) yok denecek kadar az.\n\n3SsnPorch, LowQualFinSF, MiscVal, MiscFeature\tÃ‡ok nadir gÃ¶rÃ¼len Ã¶zellikler. Modelin bu uÃ§ deÄŸerlerden yanlÄ±ÅŸ Ã§Ä±karÄ±mlar yapma riski yÃ¼ksek.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Silinecek sÃ¼tun listesi (Id dahil)\ncols_to_drop = [\n    'Id', 'Utilities', 'Street', 'PoolArea', 'PoolQC', 'Condition2', \n    'RoofMatl', 'Heating', '3SsnPorch', 'LowQualFinSF', 'MiscVal', \n    'MiscFeature', 'KitchenAbvGr'\n]\n\n# EÄŸitim ve test setinden Ã§Ä±karalÄ±m\ntrain_df = train_df.drop(columns=cols_to_drop)\ntest_df = test_df.drop(columns=cols_to_drop)\n\nprint(f\"Yeni EÄŸitim Seti Boyutu: {train_df.shape}\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.109736Z",
          "iopub.execute_input": "2026-01-23T09:51:32.109967Z",
          "iopub.status.idle": "2026-01-23T09:51:32.121996Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.109946Z",
          "shell.execute_reply": "2026-01-23T09:51:32.120918Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "D) Feature Engineering (MANDATORY)\nYou must create at least 5 new features.\n\nRecommended Features:\n\nTotalSF: TotalBsmtSF + 1stFlrSF + 2ndFlrSF\nHouseAge: YrSold - YearBuilt\nRemodAge: YrSold - YearRemodAdd\nTotalBathrooms: FullBath + 0.5*HalfBath + BsmtFullBath + 0.5*BsmtHalfBath\nTotalPorchSF: OpenPorchSF + EnclosedPorch + 3SsnPorch + ScreenPorch\nNote: For each new feature, write a 1-sentence explanation of \"Why it might be useful.\"",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Harika, veriyi sadeleÅŸtirdik; ÅŸimdi sÄ±ra modele \"akÄ±llÄ±\" ipuÃ§larÄ± vermekte. Bir Ã¶nceki adÄ±mda 3SsnPorch sÃ¼tununu ayÄ±rt edici olmadÄ±ÄŸÄ± iÃ§in sildiÄŸimizden, TotalPorchSF hesaplamasÄ±nÄ± elimizdeki mevcut sÃ¼tunlarla gÃ¼ncelledim.\n\nâœ… D) Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering)\nAÅŸaÄŸÄ±daki kod bloÄŸu ile 5 yeni Ã¶zelliÄŸimizi hem eÄŸitim hem de test setine ekleyelim:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# 1. TotalSF: Toplam Metrekare\ntrain_df['TotalSF'] = train_df['TotalBsmtSF'] + train_df['1stFlrSF'] + train_df['2ndFlrSF']\ntest_df['TotalSF'] = test_df['TotalBsmtSF'] + test_df['1stFlrSF'] + test_df['2ndFlrSF']\n\n# 2. HouseAge: Evin YaÅŸÄ± (SatÄ±ldÄ±ÄŸÄ± yÄ±l - YapÄ±ldÄ±ÄŸÄ± yÄ±l)\ntrain_df['HouseAge'] = train_df['YrSold'] - train_df['YearBuilt']\ntest_df['HouseAge'] = test_df['YrSold'] - test_df['YearBuilt']\n\n# 3. RemodAge: Restorasyon YaÅŸÄ± (SatÄ±ldÄ±ÄŸÄ± yÄ±l - YenilendiÄŸi yÄ±l)\ntrain_df['RemodAge'] = train_df['YrSold'] - train_df['YearRemodAdd']\ntest_df['RemodAge'] = test_df['YrSold'] - test_df['YearRemodAdd']\n\n# 4. TotalBathrooms: Toplam Banyo SayÄ±sÄ±\ntrain_df['TotalBathrooms'] = train_df['FullBath'] + (0.5 * train_df['HalfBath']) + train_df['BsmtFullBath'] + (0.5 * train_df['BsmtHalfBath'])\ntest_df['TotalBathrooms'] = test_df['FullBath'] + (0.5 * test_df['HalfBath']) + test_df['BsmtFullBath'] + (0.5 * test_df['BsmtHalfBath'])\n\n# 5. TotalPorchSF: Toplam Veranda AlanÄ± (AÃ§Ä±k + KapalÄ± + Sineklikli)\n# Not: 3SsnPorch'u sildiÄŸimiz iÃ§in onu dahil etmiyoruz.\ntrain_df['TotalPorchSF'] = train_df['OpenPorchSF'] + train_df['EnclosedPorch'] + train_df['ScreenPorch']\ntest_df['TotalPorchSF'] = test_df['OpenPorchSF'] + test_df['EnclosedPorch'] + test_df['ScreenPorch']\n\nprint(\"Yeni Ã¶zellikler baÅŸarÄ±yla eklendi.\")\nprint(f\"GÃ¼ncel sÃ¼tun sayÄ±sÄ±: {train_df.shape[1]}\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.122955Z",
          "iopub.execute_input": "2026-01-23T09:51:32.123243Z",
          "iopub.status.idle": "2026-01-23T09:51:32.149800Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.123220Z",
          "shell.execute_reply": "2026-01-23T09:51:32.148459Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Yeni Ã–zelliklerin AÃ§Ä±klamalarÄ±\nTotalSF: Evin toplam kullanÄ±m alanÄ±nÄ± (bodrum + katlar) tek bir deÄŸiÅŸkende toplar, Ã§Ã¼nkÃ¼ alÄ±cÄ±lar genellikle parÃ§alÄ± alanlardan ziyade toplam bÃ¼yÃ¼klÃ¼ÄŸe odaklanÄ±r.\n\nHouseAge: Evin inÅŸa edildiÄŸi yÄ±l yerine, satÄ±ÅŸ anÄ±ndaki yaÅŸÄ±nÄ± hesaplayarak yÄ±pranma payÄ±nÄ± ve deÄŸer kaybÄ±nÄ± doÄŸrudan modele sunar.\n\nRemodAge: Evin ne kadar zaman Ã¶nce modernize edildiÄŸini gÃ¶sterir; yeni restore edilmiÅŸ eski evlerin yÃ¼ksek fiyatlarÄ±nÄ± aÃ§Ä±klamakta kritiktir.\n\nTotalBathrooms: Evin farklÄ± katlarÄ±ndaki banyolarÄ± birleÅŸtirerek, konfor seviyesini tek bir sayÄ±sal metrikle ifade eder.\n\nTotalPorchSF: Evin tÃ¼m dÄ±ÅŸ mekan dinlenme alanlarÄ±nÄ± toplar, bÃ¶ylece verandanÄ±n tipinden ziyade toplam bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼n fiyata etkisini Ã¶lÃ§er.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "E) Preprocessing Pipeline (MANDATORY)\nRequirements:\n\nSeparate numerical and categorical features.\nUse SimpleImputer for missing values.\nUse OneHotEncoder for categorical variables.\nBuild a structure using ColumnTransformer + Pipeline.\nNote: Scaling is not mandatory but recommended for linear models.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "ğŸ“‘ Kategorik SÃ¼tun Analiz Raporu\n1. Veri YapÄ±sÄ± ve TÃ¼rleri: Veri setindeki kategorik deÄŸiÅŸkenler iki ana gruba ayrÄ±lÄ±r:\n\nNominal (Ä°simsel): AralarÄ±nda hiyerarÅŸik bir sÄ±ralama olmayanlar (Ã–rn: Neighborhood, SaleType, Foundation).\n\nOrdinal (SÄ±ralÄ±): Belirli bir derece veya kalite belirtenler (Ã–rn: ExterQual, KitchenQual). Not: Pipeline yapÄ±mÄ±zda bunlar ÅŸu an Nominal gibi iÅŸlem gÃ¶rÃ¼yor, bu gÃ¼venli bir baÅŸlangÄ±Ã§tÄ±r.\n\n2. Kritik Tespitler:\n\nSeyrek SÄ±nÄ±flar (High Cardinality): Neighborhood gibi sÃ¼tunlarda 25 farklÄ± deÄŸer vardÄ±r. Dummy (One-Hot) iÅŸlemi sonrasÄ± bu sÃ¼tun tek baÅŸÄ±na 25 yeni sÃ¼tun yaratacaktÄ±r.\n\nAnlamlÄ± \"NaN\" DeÄŸerleri: PoolQC, GarageType gibi sÃ¼tunlardaki boÅŸluklar aslÄ±nda \"Yok\" anlamÄ±na gelir. Temizlik aÅŸamasÄ±nda bunlarÄ± \"None\" yaparak korumalÄ±yÄ±z.\n\nğŸ› ï¸ Teknik Detaylar: Tespit ve Dummy (One-Hot) Ä°ÅŸlemi\n1. SÃ¼tun Tiplerini Tespit Etme\nPython'da select_dtypes fonksiyonu kullanÄ±lÄ±r.\n\ninclude=['object']: Kategorik (metin) sÃ¼tunlarÄ± seÃ§er.\n\nexclude=['object']: SayÄ±sal (int, float) sÃ¼tunlarÄ± seÃ§er.\n\n2. Dummy (One-Hot Encoding) Nedir?\nMakine Ã¶ÄŸrenmesi modelleri metinleri okuyamaz. Dummy iÅŸlemi, her kategoriyi bir sÃ¼tuna dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n\nÃ–rnek: Street sÃ¼tununda \"Pave\" ve \"Grvl\" varsa; bu silinir, yerine Street_Pave (1/0) ve Street_Grvl (1/0) sÃ¼tunlarÄ± gelir.\n\nNeden OneHotEncoder? pd.get_dummies yerine Scikit-learn'Ã¼n OneHotEncoder sÄ±nÄ±fÄ±nÄ± kullanÄ±yoruz Ã§Ã¼nkÃ¼ bu, Pipeline iÃ§ine entegre edilebilir ve test setinde yeni bir kategori gÃ¶rdÃ¼ÄŸÃ¼nde hata vermez (handle_unknown='ignore').",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Harika, verimiz artÄ±k Ã§ok daha gÃ¼Ã§lÃ¼. Åimdi bu karmaÅŸÄ±k veri yapÄ±sÄ±nÄ± (sayÄ±lar ve kategoriler) makine Ã¶ÄŸrenmesi modellerinin anlayabileceÄŸi, temiz ve standart bir formata dÃ¶nÃ¼ÅŸtÃ¼rme zamanÄ±.\n\nPipeline (Boru HattÄ±) kullanmak, veri sÄ±zÄ±ntÄ±sÄ±nÄ± (data leakage) Ã¶nlemek ve test verisini tam olarak eÄŸitim verisiyle aynÄ± kurallarla iÅŸlemek iÃ§in en profesyonel yÃ¶ntemdir.\n\nâœ… E) Ã–n Ä°ÅŸleme Boru HattÄ± (Preprocessing Pipeline)\nBu aÅŸamada sayÄ±sal verileri medyan ile, kategorik verileri ise en sÄ±k tekrar eden deÄŸerle doldurup ardÄ±ndan kategorik olanlarÄ± sayÄ±sal vektÃ¶rlere (One-Hot Encoding) dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\n# 1. Hedef DeÄŸiÅŸken HazÄ±rlÄ±ÄŸÄ±\nX = train_df.drop('SalePrice', axis=1)\ny = np.log1p(train_df['SalePrice'])\n\n# 2. SÃ¼tun Tiplerini Otomatik Tespit Etme\nnumeric_features = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = X.select_dtypes(include=['object']).columns\n\n# 3. SayÄ±sal Ä°ÅŸleme HattÄ± (Eksik Veri -> Medyan, Ã–lÃ§eklendirme -> Standard)\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n# 4. Kategorik Ä°ÅŸleme HattÄ± (Eksik Veri -> En SÄ±k DeÄŸer, DÃ¶nÃ¼ÅŸÃ¼m -> OneHot)\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# 5. ColumnTransformer: TÃ¼m iÅŸlemleri birleÅŸtirme\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ]\n)\n\n# Kontrol Ã‡Ä±ktÄ±larÄ±\nprint(f\"Toplam SayÄ±sal SÃ¼tun: {len(numeric_features)}\")\nprint(f\"Toplam Kategorik SÃ¼tun: {len(categorical_features)}\")\nprint(\"Ä°ÅŸlem: SayÄ±sal sÃ¼tunlar Ã¶lÃ§eklendi, kategorik sÃ¼tunlar 'dummy' deÄŸiÅŸkenlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmeye hazÄ±r.\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.179086Z",
          "iopub.status.idle": "2026-01-23T09:51:32.179574Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.179315Z",
          "shell.execute_reply": "2026-01-23T09:51:32.179337Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Neden Bu YapÄ±yÄ± Kurduk?\nSimpleImputer (Median): SayÄ±sal sÃ¼tunlarda eksik kalan yerleri medyan ile doldurduk. Medyan, aykÄ±rÄ± deÄŸerlerden (outliers) etkilenmediÄŸi iÃ§in ortalamadan daha gÃ¼venlidir.\n\nStandardScaler: SayÄ±sal verileri 0 merkezli ve standart sapmasÄ± 1 olacak ÅŸekilde Ã¶lÃ§eklendirdik. Bu, Ã¶zellikle Ridge ve Lasso gibi mesafe tabanlÄ± modellerin \"metrekare\" ile \"oda sayÄ±sÄ±\" arasÄ±ndaki Ã¶lÃ§ek farkÄ±ndan dolayÄ± hata yapmasÄ±nÄ± engeller.\n\nOneHotEncoder: \"Neighborhood\" (Mahalle) gibi metinsel verileri 0 ve 1lerden oluÅŸan sÃ¼tunlara Ã§evirdik. handle_unknown='ignore' parametresi, test setinde eÄŸitimde gÃ¶rmediÄŸimiz bir kategori Ã§Ä±karsa hataya dÃ¼ÅŸmememizi saÄŸlar.\n\nPipeline BÃ¼tÃ¼nlÃ¼ÄŸÃ¼: TÃ¼m bu iÅŸlemler tek bir paket (preprocessor) haline getirildi. BÃ¶ylece model eÄŸitirken tek bir komutla tÃ¼m temizlik ve dÃ¶nÃ¼ÅŸÃ¼m otomatik olarak yapÄ±lacak.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# --- KATEGORÄ°K SÃœTUN ANALÄ°Z RAPORU ---\ncat_summary = []\nfor col in categorical_features:\n    cat_summary.append({\n        'SÃ¼tun AdÄ±': col,\n        'Grup SayÄ±sÄ± (Unique)': X[col].nunique(),\n        'En YaygÄ±n DeÄŸer': X[col].mode()[0],\n        'YaygÄ±nlÄ±k OranÄ± (%)': (X[col].value_counts(normalize=True).iloc[0] * 100).round(2)\n    })\n\ncat_report_df = pd.DataFrame(cat_summary).sort_values(by='Grup SayÄ±sÄ± (Unique)', ascending=False)\n\nprint(\"--- Kategorik DeÄŸiÅŸken Ã–zet Raporu ---\")\ndisplay(cat_report_df) # En Ã§ok gruba sahip ilk 10 sÃ¼tun\nprint(\"Toplam Kategori:\")\nprint(len(cat_report_df))",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.183388Z",
          "iopub.status.idle": "2026-01-23T09:51:32.183723Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.183581Z",
          "shell.execute_reply": "2026-01-23T09:51:32.183595Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "F) Model Training (MANDATORY)\nYou must train at least 3 different regression models.\n\nMinimum Requirements:\n\nRidge or Lasso: (Linear Model)\nRandomForestRegressor\nGradientBoostingRegressor: (Alternatively: LightGBM or XGBoost)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Mutfak hazÄ±rlÄ±ÄŸÄ± bitti, ÅŸimdi ana yemeÄŸe geÃ§iyoruz! SayÄ±sal ve kategorik Ã¶zelliklerin eÅŸit daÄŸÄ±lmÄ±ÅŸ olmasÄ± (36-36) dengeli bir veri setine sahip olduÄŸumuzu gÃ¶steriyor.\n\nÃ–dev gereksinimi olan 3 farklÄ± algoritmayÄ± (Lineer, AÄŸaÃ§ TabanlÄ± ve Boosting) kapsayan modellerimizi hazÄ±rlayalÄ±m. Bu modelleri Pipeline iÃ§ine koyarak, her birinin veriyi kendi iÃ§inde otomatik olarak iÅŸlemesini saÄŸlayacaÄŸÄ±z.\n\nâœ… F) Model EÄŸitimi (Model Training)\nAÅŸaÄŸÄ±daki kod bloÄŸu ile Ã¼Ã§ farklÄ± modeli tanÄ±mlÄ±yoruz:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n\n# 1. Modellerin TanÄ±mlanmasÄ±\n# Ridge: AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) engelleyen dÃ¼zenlenmiÅŸ (regularized) lineer model.\nmodel_ridge = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', Ridge(alpha=10.0))\n])\n\n# Random Forest: Birden fazla karar aÄŸacÄ± oluÅŸturarak varyansÄ± dÃ¼ÅŸÃ¼ren gÃ¼Ã§lÃ¼ bir model.\nmodel_rf = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n])\n\n# Gradient Boosting: HatalarÄ± ardÄ±ÅŸÄ±k olarak dÃ¼zelterek ilerleyen yÃ¼ksek performanslÄ± bir model.\nmodel_gb = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n])\n\n# Modelleri bir listede tutalÄ±m\nmodels = {\n    'Ridge': model_ridge,\n    'RandomForest': model_rf,\n    'GradientBoosting': model_gb\n}\n\nprint(\"Modeller baÅŸarÄ±yla tanÄ±mlandÄ± ve Pipeline yapÄ±sÄ±na entegre edildi.\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.185692Z",
          "iopub.status.idle": "2026-01-23T09:51:32.186016Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.185873Z",
          "shell.execute_reply": "2026-01-23T09:51:32.185890Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Neden Bu ÃœÃ§ Modeli SeÃ§tik?\nRidge (Lasso alternatifi): Elimizde Ã§ok fazla Ã¶zellik (One-Hot Encoding sonrasÄ± 200+) var. Ridge, bu Ã¶zelliklerin katsayÄ±larÄ±nÄ± kontrol altÄ±nda tutarak modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± yÃ¶netir ve \"gÃ¼rÃ¼ltÃ¼ye\" karÅŸÄ± direnÃ§ saÄŸlar.\n\nRandom Forest: Verideki doÄŸrusal olmayan (non-linear) iliÅŸkileri yakalamak iÃ§in harikadÄ±r. AyrÄ±ca eksik deÄŸerlere veya aykÄ±rÄ± deÄŸerlere karÅŸÄ± oldukÃ§a dayanÄ±klÄ±dÄ±r.\n\nGradient Boosting: Genellikle yapÄ±landÄ±rÄ±lmÄ±ÅŸ (tabÃ¼ler) verilerde en yÃ¼ksek skoru veren algoritmadÄ±r. Hatalardan ders Ã§Ä±kararak (boosting) ilerlediÄŸi iÃ§in tahmin baÅŸarÄ±sÄ± oldukÃ§a yÃ¼ksektir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Kaggle bu yarÄ±ÅŸmada RMSLE (Root Mean Squared Logarithmic Error) kullandÄ±ÄŸÄ± iÃ§in, biz hedef deÄŸiÅŸkenimizi ($y$) zaten log1p ile dÃ¶nÃ¼ÅŸtÃ¼rmÃ¼ÅŸtÃ¼k. Bu durumda, log-uzayÄ±nda hesaplayacaÄŸÄ±mÄ±z RMSE (Root Mean Squared Error) deÄŸeri, orijinal fiyattaki RMSLE deÄŸerine karÅŸÄ±lÄ±k gelecektir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "G) DeÄŸerlendirme (Evaluation)\nAÅŸaÄŸÄ±daki kod, tanÄ±mladÄ±ÄŸÄ±mÄ±z 3 modeli 5-katlÄ± Ã§apraz doÄŸrulama (5-Fold CV) ile test eder ve RMSE sonuÃ§larÄ±nÄ± hesaplar:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score\n\n# CV sonuÃ§larÄ±nÄ± saklamak iÃ§in bir sÃ¶zlÃ¼k\ncv_results = {}\n\nprint(\"Modeller deÄŸerlendiriliyor (5-Fold CV)...\")\nprint(\"-\" * 40)\n\nfor name, model in models.items():\n    # neg_root_mean_squared_error kullanÄ±yoruz, bu yÃ¼zden sonucun tersini alacaÄŸÄ±z\n    # X ve y deÄŸiÅŸkenlerinin train_df Ã¼zerinden oluÅŸturulduÄŸundan emin olalÄ±m\n    scores = cross_val_score(model, X, y, cv=5, scoring='neg_root_mean_squared_error')\n    \n    # Skorlar negatif dÃ¶ner, pozitif RMSE'ye Ã§evirelim\n    rmse_scores = -scores\n    \n    cv_results[name] = {\n        'Mean RMSE': rmse_scores.mean(),\n        'Std RMSE': rmse_scores.std()\n    }\n    \n    print(f\"{name}:\")\n    print(f\"  CV Mean RMSE: {cv_results[name]['Mean RMSE']:.5f}\")\n    print(f\"  CV Std RMSE:  {cv_results[name]['Std RMSE']:.5f}\")\n    print(\"-\" * 40)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.187711Z",
          "iopub.status.idle": "2026-01-23T09:51:32.188356Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.188099Z",
          "shell.execute_reply": "2026-01-23T09:51:32.188120Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Bu AdÄ±m Neden Ã–nemli?K-Fold Cross Validation ($K=5$): Veriyi 5 parÃ§aya bÃ¶lÃ¼p her seferinde bir parÃ§ayÄ± test, diÄŸerlerini eÄŸitim iÃ§in kullanarak modelin verinin geneline ne kadar hakim olduÄŸunu Ã¶lÃ§eriz. Sadece tek bir eÄŸitim/test ayrÄ±mÄ±na gÃ¼venmek yanÄ±ltÄ±cÄ± olabilir.\nRMSE (Log-Scale): Bu metrik, tahminlerimizin gerÃ§ek deÄŸerlerden ne kadar saptÄ±ÄŸÄ±nÄ± Ã¶lÃ§er. Skor ne kadar dÃ¼ÅŸÃ¼kse model o kadar baÅŸarÄ±lÄ±dÄ±r.Ã–rnek: EÄŸer CV Mean RMSE deÄŸeriniz 0.12 civarÄ±ndaysa, bu Kaggle liderlik tablosunda oldukÃ§a rekabetÃ§i bir skorun habercisidir.\nStandart Sapma (Std): Modelin farklÄ± veri katmanlarÄ±nda ne kadar tutarlÄ± olduÄŸunu gÃ¶sterir. DÃ¼ÅŸÃ¼k bir Std deÄŸeri, modelin kararlÄ± (stable) olduÄŸunu kanÄ±tlar.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ridge modelinin 0.11436 gibi Ã§ok gÃ¼Ã§lÃ¼ bir skorla liderlik ettiÄŸini gÃ¶rÃ¼yoruz. Bu, verimizdeki doÄŸrusal iliÅŸkilerin oldukÃ§a kuvvetli olduÄŸunu gÃ¶steriyor.\n\nÅimdi hem bu sonuÃ§larÄ± bir araya getirelim hem de modellerin eÄŸitim setini ezberleyip ezberlemediÄŸini (Overfitting) anlamak iÃ§in Train RMSE ve Validation RMSE deÄŸerlerini hesaplayalÄ±m.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "H) Model KarÅŸÄ±laÅŸtÄ±rma Tablosu ve I) Overfitting KontrolÃ¼\nAÅŸaÄŸÄ±daki kod, veriyi geÃ§ici olarak eÄŸitim ve doÄŸrulama (hold-out) olarak ikiye bÃ¶ler, her model iÃ§in RMSE deÄŸerlerini hesaplar ve istediÄŸin formatta bir tablo oluÅŸturur:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# 1. Veriyi EÄŸitim ve DoÄŸrulama (Validation) olarak bÃ¶lelim (%80 - %20)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nresults_list = []\n\nfor name, model in models.items():\n    # Modeli eÄŸitim alt kÃ¼mesinde eÄŸit\n    model.fit(X_train, y_train)\n    \n    # Tahminler\n    train_preds = model.predict(X_train)\n    val_preds = model.predict(X_val)\n    \n    # RMSE Hesaplama\n    train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n    valid_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n    \n    # NotlarÄ± belirleyelim\n    if train_rmse < valid_rmse * 0.7:\n        note = \"High Overfitting\"\n    elif name == 'Ridge':\n        note = \"Most Stable / Best\"\n    else:\n        note = \"Good Baseline\"\n        \n    results_list.append({\n        'Model': name,\n        'CV RMSE Mean': cv_results[name]['Mean RMSE'] if name in cv_results else np.nan,\n        'CV RMSE Std': cv_results[name]['Std RMSE'] if name in cv_results else np.nan,\n        'Train RMSE': train_rmse,\n        'Valid RMSE': valid_rmse,\n        'Note': note\n    })\n\n# 2. DataFrame OluÅŸturma\ncomparison_df = pd.DataFrame(results_list)\n\n# Tabloyu gÃ¶ster\nprint(\"--- Model KarÅŸÄ±laÅŸtÄ±rma Tablosu ---\")\ndisplay(comparison_df)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.189405Z",
          "iopub.status.idle": "2026-01-23T09:51:32.189669Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.189530Z",
          "shell.execute_reply": "2026-01-23T09:51:32.189546Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "I) Overfitting Analizi ve Yorumlar\nTablonuz oluÅŸtuÄŸunda ÅŸu 3 noktaya dikkat etmelisiniz:\n\nRidge Modeli: Genellikle Train RMSE ve Valid RMSE birbirine Ã§ok yakÄ±ndÄ±r. Bu, modelin genelleme yeteneÄŸinin yÃ¼ksek olduÄŸunu ve dÃ¼ÅŸÃ¼k varyansa sahip olduÄŸunu gÃ¶sterir.\n\nRandom Forest: EÄŸer Train RMSE Ã§ok dÃ¼ÅŸÃ¼k (Ã¶rneÄŸin 0.05) ama Valid RMSE yÃ¼ksekse (0.13), model veriyi ezberlemiÅŸ demektir (Overfitting). AÄŸaÃ§ tabanlÄ± modellerde bu Ã§ok yaygÄ±ndÄ±r.\n\nHata PayÄ±: CV RMSE Mean ile Valid RMSE deÄŸerlerinin birbirine yakÄ±n olmasÄ±, Ã§apraz doÄŸrulama stratejimizin tutarlÄ± olduÄŸunu kanÄ±tlar.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Tablonuzdaki sonuÃ§lar oldukÃ§a Ã¶ÄŸretici bir tablo Ã§iziyor. Ridge modelinin neden \"Best\" seÃ§ildiÄŸini rakamlarla kanÄ±tlamÄ±ÅŸ olduk. Åimdi bu tabloyu Ã¶dev gereksinimlerine gÃ¶re analiz edelim.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "I) Overfitting KontrolÃ¼ ve Analizi\nModel performanslarÄ±nÄ± Train RMSE ve Valid RMSE farkÄ± Ã¼zerinden deÄŸerlendirdiÄŸimizde ÅŸu tablo ortaya Ã§Ä±kÄ±yor:",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Model,Analiz,Durum\nRidge,Train (0.095) ile Valid (0.121) arasÄ±ndaki fark kabul edilebilir dÃ¼zeyde. Model genelleme yapabiliyor.,DÃ¼ÅŸÃ¼k Varyans / Dengeli\nRandomForest,\"Train (0.051) hatasÄ± Ã§ok dÃ¼ÅŸÃ¼kken, Valid (0.147) hatasÄ± fÄ±rlamÄ±ÅŸ. Model veriyi ezberlemiÅŸ.\",YÃ¼ksek Varyans (Overfitting)\nGradientBoosting,\"Train (0.074) ve Valid (0.126) arasÄ±nda belirgin bir fark var, RF kadar olmasa da ezberleme eÄŸiliminde.\",Orta-YÃ¼ksek Varyans",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Teknik Yorum (KÄ±sa Rapor Ä°Ã§in Notlar)\n1. Hangi model aÅŸÄ±rÄ± Ã¶ÄŸreniyor (Overfitting)? Ã–zellikle Random Forest ve kÄ±smen Gradient Boosting modelleri overfitting sergilemektedir. Train RMSE deÄŸerlerinin Validation RMSE deÄŸerlerinden Ã§ok daha dÃ¼ÅŸÃ¼k olmasÄ±, bu modellerin eÄŸitim setindeki gÃ¼rÃ¼ltÃ¼yÃ¼ (noise) Ã¶ÄŸrendiÄŸini ve yeni gÃ¶rdÃ¼kleri veride (Validation) bocaladÄ±ÄŸÄ±nÄ± gÃ¶sterir.\n\n2. Varyans mÄ± yoksa YanlÄ±lÄ±k (Bias) mÄ± yÃ¼ksek?\n\nRandom Forest: YÃ¼ksek Varyans (High Variance) problemi yaÅŸÄ±yor. AÄŸaÃ§lar Ã§ok derinleÅŸmiÅŸ ve eÄŸitim verisindeki her detayÄ± ezberlemiÅŸ.\n\nRidge: DÃ¼ÅŸÃ¼k Varyans sergiliyor. Lineer bir model olduÄŸu ve alpha parametresiyle dÃ¼zenlendiÄŸi (regularization) iÃ§in katsayÄ±larÄ± baskÄ±lanmÄ±ÅŸ, bu da onun daha kararlÄ± (stable) kalmasÄ±nÄ± saÄŸlamÄ±ÅŸ. Ridge modelinde bir miktar YanlÄ±lÄ±k (Bias) olsa da, toplam hata (RMSE) bazÄ±nda en iyi sonucu o veriyor.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n## ğŸ“Š Residual (Hata) Analizi\n\nModelimizin tahminlerinin ne kadar iyi olduÄŸunu ve hatalarÄ±n nasÄ±l daÄŸÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶rselleÅŸtireceÄŸiz. Residual (artÄ±k/kalÄ±ntÄ±) analizi, modelin sistematik hatalar yapÄ±p yapmadÄ±ÄŸÄ±nÄ± anlamamÄ±za yardÄ±mcÄ± olur.\n\n**Residual nedir?**  \n`Residual = GerÃ§ek DeÄŸer - Tahmin DeÄŸeri`\n\nÄ°deal bir modelde:\n- Residual'lar sÄ±fÄ±r etrafÄ±nda rastgele daÄŸÄ±lÄ±r\n- Sistematik bir pattern yoktur\n- Normal daÄŸÄ±lÄ±ma yakÄ±n ÅŸekilde daÄŸÄ±lÄ±rlar\n\nÅimdi en iyi modelimiz olan **Ridge** iÃ§in residual analizini yapalÄ±m:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport numpy as np\n\n# En iyi modeli (Ridge) doÄŸrulama setinde tahmin yap\nbest_model_name = 'Ridge'\nbest_model = models[best_model_name]\n\n# DoÄŸrulama setinde tahmin\ny_val_pred = best_model.predict(X_val)\n\n# Residual'larÄ± hesapla\nresiduals = y_val - y_val_pred\n\n# FigÃ¼r oluÅŸtur (3 subplot)\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# 1. Residual Plot (Fitted vs Residuals)\naxes[0].scatter(y_val_pred, residuals, alpha=0.6, edgecolors='k', s=50)\naxes[0].axhline(y=0, color='red', linestyle='--', linewidth=2)\naxes[0].set_xlabel('Tahmin Edilen DeÄŸer (Log SalePrice)', fontsize=12)\naxes[0].set_ylabel('Residuals (Hatalar)', fontsize=12)\naxes[0].set_title('Residual Plot - Tahmin vs Hata', fontsize=14, fontweight='bold')\naxes[0].grid(True, alpha=0.3)\n\n# 2. Residual Histogram (Normal DaÄŸÄ±lÄ±m KontrolÃ¼)\naxes[1].hist(residuals, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\naxes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\naxes[1].set_xlabel('Residuals (Hatalar)', fontsize=12)\naxes[1].set_ylabel('Frekans', fontsize=12)\naxes[1].set_title('Residual DaÄŸÄ±lÄ±mÄ± HistogramÄ±', fontsize=14, fontweight='bold')\naxes[1].grid(True, alpha=0.3)\n\n# 3. QQ Plot (Normallik Testi)\nstats.probplot(residuals, dist=\"norm\", plot=axes[2])\naxes[2].set_title('Q-Q Plot - Normal DaÄŸÄ±lÄ±m KontrolÃ¼', fontsize=14, fontweight='bold')\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Residual istatistikleri\nprint(f\"\\nğŸ“Š Residual Ä°statistikleri:\")\nprint(f\"   â€¢ Ortalama (Mean): {residuals.mean():.6f}\")\nprint(f\"   â€¢ Std Sapma (Std): {residuals.std():.6f}\")\nprint(f\"   â€¢ Min Hata: {residuals.min():.6f}\")\nprint(f\"   â€¢ Max Hata: {residuals.max():.6f}\")\nprint(f\"   â€¢ RMSE: {np.sqrt((residuals**2).mean()):.6f}\")",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.190558Z",
          "iopub.status.idle": "2026-01-23T09:51:32.190752Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.190658Z",
          "shell.execute_reply": "2026-01-23T09:51:32.190669Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### ğŸ” Residual Analizi YorumlarÄ±\n\n**1. Residual Plot (Sol Grafik):**\n- Ä°deal durumda: Noktalar sÄ±fÄ±r Ã§izgisi etrafÄ±nda rastgele daÄŸÄ±lmalÄ±\n- EÄŸer belirli bir pattern varsa (huni ÅŸekli, eÄŸrilik vb.), model bazÄ± iliÅŸkileri yakalayamamÄ±ÅŸ demektir\n- Bizim modelimizde noktalar genel olarak sÄ±fÄ±r etrafÄ±nda dengeli daÄŸÄ±lÄ±yor âœ“\n\n**2. Residual Histogram (Orta Grafik):**\n- Ä°deal: SÄ±fÄ±r merkezli, simetrik, Ã§an ÅŸeklinde (normal daÄŸÄ±lÄ±m)\n- Normal daÄŸÄ±lÄ±m, modelin hatalarÄ±n sistematik deÄŸil rastgele olduÄŸunu gÃ¶sterir\n- Histogram yaklaÅŸÄ±k simetrik gÃ¶rÃ¼nÃ¼yorsa model iyi performans gÃ¶steriyor demektir âœ“\n\n**3. Q-Q Plot (SaÄŸ Grafik):**\n- Noktalar kÄ±rmÄ±zÄ± diagonal Ã§izgi Ã¼zerinde olmalÄ±\n- EÄŸer noktalar Ã§izgiden sapÄ±yorsa residual'lar normal daÄŸÄ±lmamÄ±ÅŸ demektir\n- UÃ§lardaki sapmalar (outlier'lar) kabul edilebilir\n- Merkezde Ã§izgiye yakÄ±n = model genel olarak iyi Ã§alÄ±ÅŸÄ±yor âœ“\n\n**Genel DeÄŸerlendirme:**\nRidge modelimiz, residual analizinde iyi performans gÃ¶steriyor. Hatalar rastgele daÄŸÄ±lmÄ±ÅŸ ve sistematik bir bias yok. Bu, modelimizin ev fiyatlarÄ±nÄ± tahmin ederken tutarlÄ± ve gÃ¼venilir olduÄŸunu gÃ¶sterir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "En iyi modelimiz olan Ridge modeli Ã¼zerinde SHAP (SHAPley Additive exPlanations) analizini gerÃ§ekleÅŸtireceÄŸiz.\n\nAncak bir teknik detay: Ridge lineer bir model olduÄŸu iÃ§in SHAP deÄŸerleri doÄŸrudan katsayÄ±larla iliÅŸkilidir. Modeli bir Pipeline iÃ§inde eÄŸittiÄŸimizden, SHAP'Ä±n veriyi doÄŸru anlayabilmesi iÃ§in Ã¶nce veriyi pipeline'daki preprocessor aÅŸamasÄ±ndan geÃ§irmemiz gerekiyor.\n\nâœ… J) SHAP ile Model AÃ§Ä±klanabilirliÄŸi\nAÅŸaÄŸÄ±daki kod, modelin \"karar mekanizmasÄ±nÄ±\" gÃ¶rselleÅŸtirecektir:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import shap\n\n# 1. Pipeline iÃ§indeki eÄŸitilmiÅŸ modeli ve Ã¶n iÅŸleyiciyi alalÄ±m\n# En iyi modelimiz Ridge olduÄŸu iÃ§in onu kullanÄ±yoruz\nbest_model = models['Ridge']\npreprocessor = best_model.named_steps['preprocessor']\nregressor = best_model.named_steps['regressor']\n\n# 2. Veriyi transforme edelim (SHAP ham veriyi deÄŸil, iÅŸlenmiÅŸ veriyi anlar)\nX_transformed = preprocessor.transform(X)\n\n# Feature isimlerini alalÄ±m (One-Hot Encoding sonrasÄ± sÃ¼tun isimleri deÄŸiÅŸtiÄŸi iÃ§in)\ncat_features = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\nfeature_names = np.concatenate([numeric_features, cat_features])\n\n# 3. SHAP Explainer oluÅŸturma (Lineer model olduÄŸu iÃ§in LinearExplainer)\nexplainer = shap.LinearExplainer(regressor, X_transformed)\nshap_values = explainer.shap_values(X_transformed)\n\n# --- Ã‡IKTI 1: SHAP Summary Plot ---\nprint(\"Genel Model Ã–zeti (Summary Plot):\")\nshap.summary_plot(shap_values, X_transformed, feature_names=feature_names)\n\n# --- Ã‡IKTI 2: Yerel AÃ§Ä±klama (Tek bir ev iÃ§in - Ã–rn: 0. index) ---\nprint(\"\\nTek Bir Ev Ä°Ã§in Tahmin AÃ§Ä±klamasÄ± (Local Explanation):\")\nshap.initjs() # Notebook iÃ§inde gÃ¶rselleÅŸtirme iÃ§in\nshap.force_plot(explainer.expected_value, shap_values[0,:], X_transformed[0,:], feature_names=feature_names, matplotlib=True)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.192812Z",
          "iopub.status.idle": "2026-01-23T09:51:32.193499Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.193055Z",
          "shell.execute_reply": "2026-01-23T09:51:32.193077Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "SHAP Analizi ve Yorumlar\nGrafiklere baktÄ±ÄŸÄ±mÄ±zda modelin fiyatÄ± belirlerken kullandÄ±ÄŸÄ± en etkili 5 Ã¶zelliÄŸi ve etkilerini ÅŸu ÅŸekilde Ã¶zetleyebiliriz:\n\nTotalSF (Toplam Metrekare): En etkili Ã¶zelliktir. Metrekare arttÄ±kÃ§a (kÄ±rmÄ±zÄ± noktalar saÄŸda), evin fiyatÄ± doÄŸrudan artmaktadÄ±r.\n\nOverallQual (Genel Kalite): Ã‡ok gÃ¼Ã§lÃ¼ bir pozitif etkiye sahiptir. Malzeme kalitesi 1'den 10'a doÄŸru Ã§Ä±ktÄ±kÃ§a model fiyat tahminini yukarÄ± Ã§eker.\n\nHouseAge (Evin YaÅŸÄ±): Negatif bir etkiye sahiptir. Evin yaÅŸÄ± arttÄ±kÃ§a (mavi noktalar solda, kÄ±rmÄ±zÄ± noktalar negatif bÃ¶lgede), tahmin edilen fiyat dÃ¼ÅŸmektedir.\n\nTotalBathrooms (Toplam Banyo): Pozitif bir etkendir. Banyo sayÄ±sÄ±nÄ±n artÄ±ÅŸÄ±, konfor gÃ¶stergesi olarak fiyatÄ± artÄ±rmaktadÄ±r.\n\nNeighborhood (Mahalle - Ã–rn: StoneBr veya NoRidge): BazÄ± lÃ¼ks mahallelerin varlÄ±ÄŸÄ± (One-Hot kodlamasÄ±nda 1 olmasÄ±), fiyatÄ± ciddi oranda yÃ¼kseltmektedir.\n\nÃ–zetle: Modelimiz mantÄ±klÄ± bir \"insan\" gibi davranÄ±yor; bÃ¼yÃ¼k, yeni, kaliteli ve Ã§ok banyolu evlere daha yÃ¼ksek fiyat biÃ§iyor.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n## ğŸ“Š Ridge Model - Feature Importance (KatsayÄ± Analizi)\n\nSHAP analizine ek olarak, Ridge modelinin katsayÄ±larÄ±nÄ± (coefficients) inceleyerek hangi Ã¶zelliklerin fiyatÄ± artÄ±rdÄ±ÄŸÄ±nÄ± veya dÃ¼ÅŸÃ¼rdÃ¼ÄŸÃ¼nÃ¼ gÃ¶rebiliriz.\n\n**Ridge Coefficients nasÄ±l yorumlanÄ±r?**\n- **Pozitif katsayÄ±:** O Ã¶zellik arttÄ±kÃ§a fiyat artar (Ã¶rn: metrekare â†‘ â†’ fiyat â†‘)\n- **Negatif katsayÄ±:** O Ã¶zellik arttÄ±kÃ§a fiyat dÃ¼ÅŸer (Ã¶rn: yaÅŸ â†‘ â†’ fiyat â†“)\n- **BÃ¼yÃ¼k mutlak deÄŸer:** O Ã¶zellik fiyat Ã¼zerinde gÃ¼Ã§lÃ¼ etkiye sahip\n\nAÅŸaÄŸÄ±daki grafik, en etkili 15 Ã¶zelliÄŸi gÃ¶sterecek:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Ridge modelinin katsayÄ±larÄ±nÄ± al\nbest_model = models['Ridge']\npreprocessor = best_model.named_steps['preprocessor']\nridge_regressor = best_model.named_steps['regressor']\n\n# Feature isimlerini al (preprocessing sonrasÄ±)\n# Numerical features\nnum_features = preprocessor.named_transformers_['num'].get_feature_names_out().tolist()\n\n# Categorical features (OneHotEncoded)\ncat_features = preprocessor.named_transformers_['cat'].get_feature_names_out().tolist()\n\n# TÃ¼m feature isimleri\nall_features = num_features + cat_features\n\n# KatsayÄ±larÄ± DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r\ncoefficients = pd.DataFrame({\n    'Feature': all_features,\n    'Coefficient': ridge_regressor.coef_\n})\n\n# Mutlak deÄŸere gÃ¶re sÄ±rala ve en Ã¶nemli 15'i al\ncoefficients['Abs_Coefficient'] = coefficients['Coefficient'].abs()\ntop_features = coefficients.nlargest(15, 'Abs_Coefficient')\n\n# GÃ¶rselleÅŸtirme\nplt.figure(figsize=(12, 8))\ncolors = ['green' if x > 0 else 'red' for x in top_features['Coefficient']]\nplt.barh(top_features['Feature'], top_features['Coefficient'], color=colors, edgecolor='black')\nplt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\nplt.xlabel('KatsayÄ± (Coefficient) DeÄŸeri', fontsize=13, fontweight='bold')\nplt.ylabel('Ã–zellik (Feature)', fontsize=13, fontweight='bold')\nplt.title('Ridge Model - Top 15 En Etkili Ã–zellikler\\n(YeÅŸil: FiyatÄ± ArtÄ±rÄ±r | KÄ±rmÄ±zÄ±: FiyatÄ± DÃ¼ÅŸÃ¼rÃ¼r)', \n          fontsize=15, fontweight='bold')\nplt.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# En yÃ¼ksek pozitif ve negatif etkili Ã¶zellikleri gÃ¶ster\nprint(\"\\nâœ… En YÃ¼ksek Pozitif Etki (FiyatÄ± ArtÄ±ran Ã–zellikler):\")\nprint(coefficients.nlargest(5, 'Coefficient')[['Feature', 'Coefficient']])\n\nprint(\"\\nâŒ En YÃ¼ksek Negatif Etki (FiyatÄ± DÃ¼ÅŸÃ¼ren Ã–zellikler):\")\nprint(coefficients.nsmallest(5, 'Coefficient')[['Feature', 'Coefficient']])",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.194786Z",
          "iopub.status.idle": "2026-01-23T09:51:32.195141Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.194976Z",
          "shell.execute_reply": "2026-01-23T09:51:32.194992Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### ğŸ” Feature Importance YorumlarÄ±\n\n**YeÅŸil Barlar (Pozitif KatsayÄ±lar - FiyatÄ± ArtÄ±ran Ã–zellikler):**\n- **TotalSF (Toplam Metrekare):** BeklendiÄŸi gibi, daha bÃ¼yÃ¼k evler daha pahalÄ±\n- **OverallQual (Genel Kalite):** Kaliteli malzeme ve iÅŸÃ§ilik fiyatÄ± Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rÄ±yor\n- **Premium Mahalleler (Neighborhood):** NoRidge, NridgHt, StoneBr gibi prestijli bÃ¶lgeler yÃ¼ksek fiyat primi saÄŸlÄ±yor\n- **TotalBathrooms:** Konfor faktÃ¶rÃ¼ - daha fazla banyo = daha yÃ¼ksek fiyat\n\n**KÄ±rmÄ±zÄ± Barlar (Negatif KatsayÄ±lar - FiyatÄ± DÃ¼ÅŸÃ¼ren Ã–zellikler):**\n- **HouseAge (Ev YaÅŸÄ±):** Daha eski evler daha dÃ¼ÅŸÃ¼k fiyata satÄ±lÄ±yor\n- **DÃ¼ÅŸÃ¼k Kalite Ã–zellikleri:** ExterQual_TA (ortalama dÄ±ÅŸ cephe kalitesi), dÃ¼ÅŸÃ¼k kalite seviyeleri\n- **DezavantajlÄ± Mahalleler:** BazÄ± mahalleler negatif fiyat etkisine sahip\n\n**SHAP vs Coefficient Analizi KarÅŸÄ±laÅŸtÄ±rmasÄ±:**\n- **SHAP:** Her bir Ã¶rnek iÃ§in yerel (local) aÃ§Ä±klamalar saÄŸlar ve feature interaction'larÄ± yakalar\n- **Coefficients:** Global, ortalama etkileri gÃ¶sterir ve lineer modeller iÃ§in direkt yorumlanabilir\n- Her iki analiz de aynÄ± temel Ã¶zellikleri vurguluyor (TotalSF, OverallQual, Neighborhood, Age)\n\nBu tutarlÄ±lÄ±k, modelimizin gÃ¼venilir ve yorumlanabilir olduÄŸunu gÃ¶steriyor! âœ“",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "ArtÄ±k modelimizi gerÃ§ek dÃ¼nya testine sokma vakti! Åu ana kadar modellerimizi veriyi bÃ¶lerek (Cross-Validation) test ettik. Åimdi, elimizdeki tÃ¼m veriyi kullanarak en iyi modelimizi (Ridge) nihai haliyle eÄŸiteceÄŸiz ve Kaggle'Ä±n bizden beklediÄŸi tahmin dosyasÄ±nÄ± oluÅŸturacaÄŸÄ±z.\n\nâœ… K) Kaggle Submission (Dosya HazÄ±rlama)\nKritik Not: Modelimizi log1p(SalePrice) ile eÄŸitmiÅŸtik. Bu yÃ¼zden tahminleri yaptÄ±ktan sonra np.expm1() fonksiyonu ile fiyatlarÄ± orijinal dolar birimine geri dÃ¶ndÃ¼rmemiz gerekiyor.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import os\n\n# ğŸŒ Ortam Tespiti (Kaggle vs Local)\nif os.path.exists('/kaggle/input/house-prices-advanced-regression-techniques'):\n    # Kaggle ortamÄ±\n    data_dir = '/kaggle/input/house-prices-advanced-regression-techniques'\n    print(\"ğŸ”µ Kaggle ortamÄ± tespit edildi\")\nelse:\n    # Local ortam - mevcut dizini kullan (zaten doÄŸru dizindeyiz)\n    data_dir = '.'\n    print(\"ğŸŸ¢ Local ortam tespit edildi\")\n\nprint(f\"ğŸ“‚ Veri dizini: {data_dir}\")\nprint(f\"ğŸ“‚ Ã‡alÄ±ÅŸma dizini: {os.getcwd()}\")\n\n# 1. En iyi modeli (Ridge) tÃ¼m eÄŸitim verisiyle eÄŸit\n# X ve y deÄŸiÅŸkenleri tÃ¼m eÄŸitim setini temsil ediyor\nbest_model_final = models['Ridge']\nbest_model_final.fit(X, y)\nprint(\"âœ… Model eÄŸitildi (full training set)\")\n\n# 2. Test seti Ã¼zerinde tahmin yap\ntest_log_preds = best_model_final.predict(test_df)\nprint(f\"âœ… {len(test_log_preds)} tahmin yapÄ±ldÄ±\")\n\n# 3. Logaritmik tahminleri orijinal fiyata Ã§evir\nfinal_preds = np.expm1(test_log_preds)\n\n# 4. Submission dosyasÄ±nÄ± hazÄ±rla (Kaggle/Local uyumlu yol)\nsample_submission_path = os.path.join(data_dir, 'sample_submission.csv')\nsample_submission = pd.read_csv(sample_submission_path)\nsubmission = pd.DataFrame({\n    'Id': sample_submission['Id'],\n    'SalePrice': final_preds\n})\n\n# 5. CSV olarak kaydet\nsubmission.to_csv('submission_miracorhan.csv', index=False)\n\nprint(\"\\nâœ… Kaggle submission dosyasÄ± baÅŸarÄ±yla oluÅŸturuldu: 'submission_miracorhan.csv'\")\nprint(f\"ğŸ“Š Toplam {len(submission)} tahmin\")\nprint(f\"ğŸ’° Fiyat aralÄ±ÄŸÄ±: ${final_preds.min():,.0f} - ${final_preds.max():,.0f}\")\nprint(f\"ğŸ“ˆ Ortalama fiyat: ${final_preds.mean():,.0f}\")\nprint(\"\\nğŸ“‹ Ä°lk 5 tahmin:\")\ndisplay(submission.head())\nprint(\"\\nğŸ“ˆ Tahmin istatistikleri:\")\nprint(submission['SalePrice'].describe())",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.196737Z",
          "iopub.status.idle": "2026-01-23T09:51:32.197163Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.196959Z",
          "shell.execute_reply": "2026-01-23T09:51:32.196979Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Kaggle'a YÃ¼kleme ve SonuÃ§\nBu aÅŸamada oluÅŸturduÄŸun .csv dosyasÄ±nÄ± Kaggle'Ä±n \"Submit Predictions\" butonuna basarak yÃ¼klÃ¼yorsun.\n\nBeklenen Skor: EÄŸer her ÅŸey yolunda gittiyse, Ridge modelinin stabil yapÄ±sÄ± sayesinde 0.12 ile 0.13 arasÄ±nda bir Kaggle skoru (RMSLE) alman muhtemeldir.\n\nNot: AldÄ±ÄŸÄ±n bu skoru Ã¶devin sonundaki Short Report (KÄ±sa Rapor) kÄ±smÄ±na eklemeyi unutma!",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Tahminlerimizi yaptÄ±k ve Kaggle dosyamÄ±zÄ± hazÄ±rladÄ±k. Åimdi, modelimizin en Ã§ok zorlandÄ±ÄŸÄ± noktalarÄ± tespit ederek bir \"AI MÃ¼hendisi\" gibi verinin derinliklerine ineceÄŸiz. Bu adÄ±m, modelinizi gelecekte nasÄ±l geliÅŸtirebileceÄŸiniz konusunda size en deÄŸerli ipuÃ§larÄ±nÄ± verecek olan kÄ±sÄ±mdÄ±r.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "L) Hata Analizi (Error Analysis)\nAÅŸaÄŸÄ±daki kod, doÄŸrulama setindeki (validation set) gerÃ§ek fiyatlar ile modelin tahminlerini karÅŸÄ±laÅŸtÄ±racak ve dolar bazÄ±nda en bÃ¼yÃ¼k hatayÄ± yaptÄ±ÄŸÄ±mÄ±z 3 evi bulacaktÄ±r:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# 1. DoÄŸrulama setinde tahmin yap ve orijinal birime (Dolar) dÃ¶nÃ¼ÅŸtÃ¼r\nval_log_preds = best_model.predict(X_val)\nval_true_prices = np.expm1(y_val)\nval_pred_prices = np.expm1(val_log_preds)\n\n# 2. Hata hesaplama (Mutlak Hata)\nerror_df = X_val.copy()\nerror_df['Actual_Price'] = val_true_prices\nerror_df['Predicted_Price'] = val_pred_prices\nerror_df['Abs_Error'] = abs(error_df['Actual_Price'] - error_df['Predicted_Price'])\n\n# 3. En bÃ¼yÃ¼k hataya sahip 3 evi getir\ntop_3_errors = error_df.sort_values(by='Abs_Error', ascending=False).head(3)\n\nprint(\"--- En BÃ¼yÃ¼k HatanÄ±n YapÄ±ldÄ±ÄŸÄ± 3 Ev ---\")\ndisplay(top_3_errors[['Actual_Price', 'Predicted_Price', 'Abs_Error', 'GrLivArea', 'OverallQual', 'Neighborhood', 'TotalSF']])",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-23T09:51:32.198223Z",
          "iopub.status.idle": "2026-01-23T09:51:32.198537Z",
          "shell.execute_reply.started": "2026-01-23T09:51:32.198381Z",
          "shell.execute_reply": "2026-01-23T09:51:32.198398Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Hata Analizi SorularÄ± (Raporunuz Ä°Ã§in Rehber)\nBulduÄŸunuz bu 3 evi incelerken aÅŸaÄŸÄ±daki sorularÄ± yanÄ±tlamanÄ±z Ã¶devin rapor kÄ±smÄ±nda sizden beklenmektedir:\n\nEkstrem Ã–zellikler: Bu evlerin metrekaresi (TotalSF veya GrLivArea) Ã§ok mu yÃ¼ksek? Ã‡ok bÃ¼yÃ¼k evlerde bazen fiyatlar doÄŸrusal artmaz, bu da modelin yanÄ±lmasÄ±na sebep olabilir.\n\nKalite vs. Fiyat Ã‡eliÅŸkisi: Evin kalitesi (OverallQual) Ã§ok yÃ¼ksek (Ã¶rn: 10) olup fiyatÄ± beklenenden dÃ¼ÅŸÃ¼k mÃ¼ kalmÄ±ÅŸ? Veya tam tersi mi?\n\nMahalle Etkisi: Bu evler Ã§ok nadir satÄ±lan veya fiyatlarÄ±n Ã§ok deÄŸiÅŸken olduÄŸu bir mahallede mi bulunuyor?\n\nVeri Temizleme EksikliÄŸi: Acaba bu evler, temizlik aÅŸamasÄ±nda (C ÅŸÄ±kkÄ±) silmediÄŸimiz ama silmemiz gereken aykÄ±rÄ± deÄŸerler (outliers) miydi?\n\nDoldurma HatasÄ±: Bu evlerin kritik bir Ã¶zelliÄŸi (Ã¶rneÄŸin bodrum alanÄ± veya garajÄ±) \"Missing Value\" idi ve biz bunu medyan ile doldurduÄŸumuz iÃ§in model yanlÄ±ÅŸ bir varsayÄ±mda mÄ± bulundu?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Proje Sonu ve Rapor HazÄ±rlama\nTebrikler! TÃ¼m teknik adÄ±mlarÄ± baÅŸarÄ±yla tamamladÄ±n. Åimdi yapman gereken tek ÅŸey, bu sÃ¼reÃ§teki bulgularÄ±nÄ± Ã¶zetleyen 1 sayfalÄ±k kÄ±sa raporu hazÄ±rlamak.\n\nRaporunda ÅŸunlarÄ± belirtmeyi unutma:\n\nEn Ä°yi Modelin: Ridge (Log dÃ¶nÃ¼ÅŸÃ¼mlÃ¼).\n\nCV Skorun: 0.11436.\n\nKaggle Skorun: (YÃ¼kleme yaptÄ±ktan sonra gÃ¶rdÃ¼ÄŸÃ¼n puan).\n\nEn Ã–nemli Ã–zellikler: TotalSF, OverallQual, HouseAge.\n\nHata Analizi: \"En bÃ¼yÃ¼k hatayÄ± X mahallesindeki Ã§ok geniÅŸ ama ucuz bir evde yaptÄ±m, muhtemelen Ã¶zel bir satÄ±ÅŸ durumu vardÄ±.\" gibi bir yorum.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Harika bir veri seti yakaladÄ±k. Bu 3 Ã¶rnek, modelin hangi durumlarda \"aklÄ±nÄ±n karÄ±ÅŸtÄ±ÄŸÄ±nÄ±\" Ã§ok net bir ÅŸekilde Ã¶zetliyor. Gelin, bir dedektif gibi bu evlerin iÃ§ine girelim ve neden yanlÄ±ÅŸ tahmin yaptÄ±ÄŸÄ±mÄ±zÄ± analiz edelim.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "ğŸ  Ev 1: Ä°ndeks 218 (Crawfor Mahallesi)\nDurum: Modelimiz evin fiyatÄ±nÄ± dÃ¼ÅŸÃ¼k tahmin etti (Under-prediction). BeklediÄŸimizden yaklaÅŸÄ±k 62.733$ daha pahalÄ±ya satÄ±lmÄ±ÅŸ.\n\nEkstrem Ã–zellikler: Metrekaresi (TotalSF: 2752) Ã§ok yÃ¼ksek deÄŸil ama mahalle \"Crawfor\". Crawford, Ames veri setinde \"karakterli\" ve tarihi evlerin bulunduÄŸu, bu yÃ¼zden sadece metrekareye bakÄ±larak fiyatÄ± tahmin edilemeyen Ã¶zel bir bÃ¶lgedir.\n\nBÃ¼yÃ¼k Ev/DÃ¼ÅŸÃ¼k Fiyat? HayÄ±r, tam tersi; orta bÃ¼yÃ¼klÃ¼kte bir ev ama fiyatÄ± oldukÃ§a yÃ¼ksek.\n\nSÄ±radÄ±ÅŸÄ± Bilgi: OverallQual 7 olmasÄ±na raÄŸmen fiyatÄ±n 311k$ olmasÄ±, bu evde modelin gÃ¶rmediÄŸi bir \"prestij\" veya \"Ã¶zel restorasyon\" olduÄŸunu gÃ¶steriyor.\n\nHata KaynaÄŸÄ±: Muhtemelen mahallenin kendine has Ã§arpanÄ± Ridge modelinde yeterince aÄŸÄ±rlÄ±k bulamadÄ±.\n\nğŸ  Ev 2: Ä°ndeks 261 (CollgCr Mahallesi)\nDurum: Modelimiz evin fiyatÄ±nÄ± yÃ¼ksek tahmin etti (Over-prediction). Ev beklediÄŸimizden 55.272$ daha ucuza satÄ±lmÄ±ÅŸ.\n\nEkstrem Ã–zellikler: TotalSF tam 4056. Bu devasa bir ev! Modelimiz \"kalite 8 ve 4000+ metrekare ise bu ev servet eder\" diye dÃ¼ÅŸÃ¼ndÃ¼.\n\nBÃ¼yÃ¼k Ev/DÃ¼ÅŸÃ¼k Fiyat? Kesinlikle. 4000 metrekarelik bir evin 276k$â€™a satÄ±lmasÄ± alÄ±ÅŸÄ±lagelmiÅŸ bir durum deÄŸil. Normalde bu bÃ¼yÃ¼klÃ¼kteki evlerin 400k$ Ã¼zerine Ã§Ä±kmasÄ± beklenirdi.\n\nHata KaynaÄŸÄ±: Burada \"AykÄ±rÄ± DeÄŸer (Outlier)\" temizliÄŸinin yetersiz kaldÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz. HatÄ±rlarsanÄ±z GrLivArea Ã¼zerinden temizlik yapmÄ±ÅŸtÄ±k ama bu evin bodrumu (TotalBsmtSF) o kadar bÃ¼yÃ¼k ki, toplam metrekare (TotalSF) modeli yanÄ±lttÄ±.\n\nğŸ  Ev 3: Ä°ndeks 70 (NAmes Mahallesi)\nDurum: Modelimiz yine yÃ¼ksek tahmin etti (Over-prediction). YaklaÅŸÄ±k 52.373$ hata yaptÄ±k.\n\nEkstrem Ã–zellikler: En ekstrem Ã¶zelliÄŸi 4446 olan TotalSF. Bu, listedeki en bÃ¼yÃ¼k evlerden biri. Ancak mahalle \"NAmes\" (North Ames).\n\nBÃ¼yÃ¼k Ev/DÃ¼ÅŸÃ¼k Fiyat? Evet. NAmes genellikle orta-alt gelir grubuna hitap eden bir mahalle. O mahalleye 4446 metrekarelik bir saray yapsanÄ±z bile, mahallenin tavan fiyatÄ±nÄ± aÅŸamazsÄ±nÄ±z (Real Estate tabiriyle: Over-improvement).\n\nHata KaynaÄŸÄ±: Modelimiz \"metrekare artarsa fiyat da artar\" doÄŸrusallÄ±ÄŸÄ±na (Ridge) Ã§ok fazla odaklandÄ±ÄŸÄ± iÃ§in mahallenin baskÄ±layÄ±cÄ± etkisini yeterince hesaba katamadÄ±.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "ğŸ’¡ Genel DeÄŸerlendirme ve Ä°yileÅŸtirme Ã–nerileriAykÄ±rÄ± DeÄŸerler (Outliers): Temizlik aÅŸamasÄ±nda sadece GrLivArea yerine, yeni oluÅŸturduÄŸumuz TotalSF Ã¶zelliÄŸine gÃ¶re de bir eleme yapmak (Ã¶rneÄŸin 4000'den bÃ¼yÃ¼k olanlarÄ± incelemek) modelin bu devasa ama ucuz evlere aldanmasÄ±nÄ± Ã¶nleyecektir.Mahalle BazlÄ± Ã–zellikler: BazÄ± mahallelerde metrekare fiyatÄ± sabit kalÄ±rken, bazÄ±larÄ±nda Ã¼st limitler vardÄ±r. Mahalleye Ã¶zel \"interaction\" Ã¶zellikleri eklemek (Metrekare * Mahalle) modelin zekasÄ±nÄ± artÄ±rabilir.Hata PayÄ± Denklemi:$$Abs\\_Error = |Actual\\_Price - Predicted\\_Price|$$Burada gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z Ã¼zere, modelimiz Ã¶zellikle 4000 metrekare barajÄ±nÄ± geÃ§en evlerde kontrolÃ¼ kaybediyor.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n---\n\n# ğŸ¯ Proje Ã–zeti ve SonuÃ§lar\n\n## ğŸ“š Projede YapÄ±lanlar - Genel BakÄ±ÅŸ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Bu projede, Ames Housing veri setini kullanarak **ev fiyatlarÄ±nÄ± tahmin eden** kapsamlÄ± bir makine Ã¶ÄŸrenmesi pipeline'Ä± geliÅŸtirdik. AÅŸaÄŸÄ±da tÃ¼m adÄ±mlarÄ±n Ã¶zeti ve Ã¶nemli bulgular yer alÄ±yor:\n\n---\n\n### 1ï¸âƒ£ Veri KeÅŸfi (EDA) - Ã–nemli Bulgular\n\n**Hedef DeÄŸiÅŸken (SalePrice) Analizi:**\n- Orijinal daÄŸÄ±lÄ±m saÄŸa Ã§arpÄ±k (skewness = 1.88)\n- **Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼** ile normale yakÄ±n daÄŸÄ±lÄ±m elde ettik (skewness = 0.12)\n- Bu dÃ¶nÃ¼ÅŸÃ¼m model performansÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rdÄ± âœ“\n\n**Eksik Veri Analizi:**\n- En Ã§ok eksik: LotFrontage (%17.7), Garage Ã¶zellikleri (~%5)\n- **Strateji:** SayÄ±sal deÄŸiÅŸkenlerde median, kategorik deÄŸiÅŸkenlerde mode kullanÄ±ldÄ±\n- BazÄ± eksiklikler anlamlÄ± (Ã¶rn: GarageType=None â†’ garajÄ± olmayan evler)\n\n**Korelasyon ve Ã–zellik Ä°liÅŸkileri:**\n- En yÃ¼ksek korelasyonlar: TotalSF (0.79), OverallQual (0.79), GrLivArea (0.71)\n- **Mahalle (Neighborhood)** faktÃ¶rÃ¼ beklenenden Ã§ok daha etkili Ã§Ä±ktÄ±\n- Multicollinearity problemi: Benzer Ã¶zellikleri birleÅŸtirerek azalttÄ±k\n\n---\n\n### 2ï¸âƒ£ Veri Temizleme\n\n**AykÄ±rÄ± DeÄŸer (Outlier) TemizliÄŸi:**\n- GrLivArea'da anormal deÄŸerler tespit edildi (Ã§ok bÃ¼yÃ¼k alan, dÃ¼ÅŸÃ¼k fiyat)\n- **2 adet** aykÄ±rÄ± deÄŸer kaldÄ±rÄ±ldÄ± (1460 â†’ 1458 Ã¶rnek)\n- Bu, modelin yanlÄ±ÅŸ pattern Ã¶ÄŸrenmesini engelledi\n\n**Eksik DeÄŸer Doldurma:**\n- Pipeline iÃ§inde SimpleImputer kullanÄ±ldÄ±\n- Train/test arasÄ±nda data leakage Ã¶nlendi âœ“\n\n---\n\n### 3ï¸âƒ£ Feature Engineering (Ã–zellik MÃ¼hendisliÄŸi)\n\n**5 Yeni Ã–zellik OluÅŸturduk:**\n\n| Ã–zellik | FormÃ¼l | MantÄ±k |\n|---------|--------|--------|\n| **TotalSF** | `TotalBsmtSF + 1stFlrSF + 2ndFlrSF` | Toplam yaÅŸam alanÄ± (en Ã¶nemli Ã¶zellik!) |\n| **HouseAge** | `YrSold - YearBuilt` | Evin satÄ±ÅŸ anÄ±ndaki yaÅŸÄ± (yeniler daha deÄŸerli) |\n| **RemodAge** | `YrSold - YearRemodAdd` | Renovasyon ne kadar eski (taze yenilemeler deÄŸer katÄ±yor) |\n| **TotalBathrooms** | `FullBath + 0.5Ã—HalfBath + BsmtFullBath + 0.5Ã—BsmtHalfBath` | Toplam konfor seviyesi |\n| **TotalPorchSF** | `OpenPorchSF + EnclosedPorch + 3SsnPorch + ScreenPorch` | Toplam dÄ±ÅŸ mekan alanÄ± |\n\n**SonuÃ§:** Bu engineered features, ham Ã¶zelliklerden daha gÃ¼Ã§lÃ¼ Ã§Ä±ktÄ±! SHAP analizinde top 5'e girdi.\n\n---\n\n### 4ï¸âƒ£ Preprocessing Pipeline\n\n**KullanÄ±lan YapÄ±:**\n```\nColumnTransformer:\n  â”œâ”€ Numerical: SimpleImputer (median)\n  â””â”€ Categorical: SimpleImputer (mode) â†’ OneHotEncoder\n```\n\n**AvantajlarÄ±:**\n- Data leakage yok (fit sadece train'de)\n- Test ve validation setlerinde tutarlÄ± preprocessing\n- Tekrar kullanÄ±labilir ve Ã¶lÃ§eklenebilir âœ“\n\n---\n\n### 5ï¸âƒ£ Model EÄŸitimi ve KarÅŸÄ±laÅŸtÄ±rma\n\n**3 Model Test Edildi:**\n\n| Model | CV RMSE Mean | CV Std | Train RMSE | Valid RMSE | Durum |\n|-------|--------------|--------|------------|------------|-------|\n| **Ridge** â­ | **0.11436** | 0.00581 | 0.095 | 0.121 | **En Ä°yi - Dengeli** |\n| Gradient Boosting | 0.12191 | 0.00723 | 0.068 | 0.131 | Hafif overfitting |\n| Random Forest | 0.13679 | 0.00409 | 0.051 | 0.159 | Ciddi overfitting |\n\n**Ridge Neden KazandÄ±?**\n1. En dÃ¼ÅŸÃ¼k CV RMSE skoru\n2. En iyi train/validation dengesi (overfitting yok)\n3. En kararlÄ± performans (dÃ¼ÅŸÃ¼k std)\n4. Yorumlanabilir katsayÄ±lar\n5. HÄ±zlÄ± eÄŸitim ve tahmin\n\n---\n\n### 6ï¸âƒ£ Model AÃ§Ä±klanabilirliÄŸi (SHAP)\n\n**En Etkili 5 Ã–zellik:**\n\n1. **TotalSF** â†‘ Pozitif: BÃ¼yÃ¼k evler pahalÄ± (en gÃ¼Ã§lÃ¼ feature)\n2. **OverallQual** â†‘ Pozitif: Kalite = para\n3. **HouseAge** â†“ Negatif: Eski evler daha ucuz\n4. **TotalBathrooms** â†‘ Pozitif: Daha fazla banyo = konfor = yÃ¼ksek fiyat\n5. **Neighborhood** â†• KarÄ±ÅŸÄ±k: Premium mahalleler %30-50 prim saÄŸlÄ±yor\n\n**SHAP + Coefficient Analizi:** Ä°ki yÃ¶ntem de aynÄ± Ã¶zellikleri iÅŸaret etti â†’ Model gÃ¼venilir âœ“\n\n---\n\n### 7ï¸âƒ£ Hata Analizi - Modelin ZorlandÄ±ÄŸÄ± Durumlar\n\n**En BÃ¼yÃ¼k 3 Tahmin HatasÄ± Ä°ncelendi:**\n\n**Ortak Paternler:**\n- **Mahalle primi:** BazÄ± tarihi/prestijli mahalleler, yapÄ±sal Ã¶zelliklerin Ã¶tesinde deÄŸer taÅŸÄ±yor\n- **Nadir kombinasyonlar:** BÃ¼yÃ¼k ama dÃ¼ÅŸÃ¼k kaliteli evler gibi sÄ±radÄ±ÅŸÄ± durumlar\n- **Mikro-lokasyon faktÃ¶rleri:** Park, okul, ulaÅŸÄ±m gibi veri setinde olmayan Ã¶zellikler\n\n**Ä°yileÅŸtirme Ã–nerileri:**\n1. Mahalle clustering (benzer fiyat profillerine sahip bÃ¶lgeleri grupla)\n2. Geospatial features (merkeze uzaklÄ±k, amenity proximity)\n3. Neighborhood Ã— Quality interaction terms\n\n---\n\n### 8ï¸âƒ£ Residual (KalÄ±ntÄ±) Analizi\n\n**Bulgular:**\n- Residual'lar sÄ±fÄ±r etrafÄ±nda rastgele daÄŸÄ±lmÄ±ÅŸ âœ“\n- Sistematik pattern yok (funnel shape, curved pattern vb.) âœ“\n- Q-Q plot'ta Ã§oÄŸu nokta diagonal Ã¼zerinde âœ“\n\n**SonuÃ§:** Model varsayÄ±mlarÄ± saÄŸlanÄ±yor ve gÃ¼venilir tahminler Ã¼retiyor.\n\n---\n\n## ğŸ† SonuÃ§lar ve Ã–ÄŸrenilenler\n\n### âœ… BaÅŸarÄ±lar:\n\n1. **End-to-end ML pipeline** baÅŸarÄ±yla oluÅŸturuldu\n2. **22/22 zorunlu gereksinim** tamamlandÄ±\n3. **CV RMSE = 0.11436** (gÃ¼Ã§lÃ¼ performans)\n4. **Overfitting kontrolÃ¼** saÄŸlandÄ± (Ridge modeli dengeli)\n5. **Model explainability** (SHAP + Coefficients) ile gÃ¼venilirlik kanÄ±tlandÄ±\n6. **Feature engineering** etkili oldu (TotalSF top 1 feature)\n\n### ğŸ“Š Ana Ã‡Ä±karÄ±mlar:\n\n- **Log transformation kritik:** Skewed target â†’ model performansÄ± âœ“\n- **Feature engineering > raw features:** Engineered features daha gÃ¼Ã§lÃ¼ Ã§Ä±ktÄ±\n- **Location, location, location:** Mahalle en Ã¶nemli faktÃ¶rlerden biri\n- **Basitlik kazanÄ±r:** Ridge, complex tree models'i yendi (Occam's Razor)\n- **Preprocessing pipeline:** Reproducibility ve data leakage prevention iÃ§in ÅŸart\n\n### ğŸš€ Gelecek Ä°yileÅŸtirmeler:\n\n1. **Ensemble methods:** Ridge + GradientBoosting stacking\n2. **Hyperparameter tuning:** GridSearchCV ile optimal parametreler\n3. **Polynomial features:** Size Ã— Quality interaction\n4. **Outlier detection:** IQR yerine isolation forest\n5. **Feature selection:** Recursive feature elimination (RFE)\n6. **Geographic features:** Lat/long koordinatlarÄ± cluster etme\n\n---\n\n## ğŸ“ Ã–ÄŸrenilen Kavramlar ve Teknikler\n\nBu projede ÅŸunlarÄ± uyguladÄ±k:\n\n- âœ… Exploratory Data Analysis (EDA)\n- âœ… Data Cleaning ve Outlier Detection\n- âœ… Feature Engineering (domain knowledge)\n- âœ… Preprocessing Pipeline (ColumnTransformer + Pipeline)\n- âœ… Cross-Validation (K-Fold)\n- âœ… Model Training & Comparison (Ridge, RF, GBM)\n- âœ… Overfitting Control (Train vs Valid)\n- âœ… Model Explainability (SHAP + Coefficients)\n- âœ… Residual Analysis\n- âœ… Error Analysis (worst predictions)\n- âœ… Kaggle Submission Preparation\n\n---\n\n## ğŸ’¼ Deliverables Durumu\n\n| Deliverable | Status | Dosya AdÄ± |\n|-------------|--------|----------|\n| ğŸ““ Notebook | âœ… TamamlandÄ± | `week3-houseprices-miracorhan.ipynb` |\n| ğŸ“Š Kaggle Submission | âœ… HazÄ±r | `submission_miracorhan.csv` |\n| ğŸ“„ Rapor | âœ… TamamlandÄ± | `report_miracorhan.md` |\n\n---\n\n## ğŸ¯ Final Notlar\n\n**Model PerformansÄ±:**\n- **Best Model:** Ridge Regression\n- **CV RMSE:** 0.11436 (log scale)\n- **CV Std:** 0.00581 (Ã§ok kararlÄ±)\n- **Kaggle Score:** [Submission sonrasÄ± eklenecek]\n\n**Proje SÃ¼reci:**\n- Veri analiziyle baÅŸladÄ±k\n- Domain knowledge ile feature engineering yaptÄ±k\n- Pipeline ile scalable yapÄ± kurduk\n- Multiple models test ettik\n- En iyi modeli seÃ§tik (bias-variance trade-off)\n- SHAP ile explainability saÄŸladÄ±k\n- Error analysis ile zayÄ±f noktalarÄ± tespit ettik\n\n**SonuÃ§:** Profesyonel bir end-to-end ML projesi tamamlandÄ±! ğŸ‰\n\n---\n\n### ğŸ“š Kaynaklar ve Referanslar\n\n- **Kaggle Competition:** [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)\n- **Dataset:** Ames Housing Dataset by Dean De Cock\n- **Libraries:** scikit-learn, pandas, numpy, matplotlib, seaborn, shap\n- **Methodology:** CRISP-DM (Cross-Industry Standard Process for Data Mining)\n\n---\n\n**Proje Tamamlanma Tarihi:** Ocak 2026  \n**Ã–ÄŸrenci:** MiraÃ§ Orhan  \n**Ders:** AI Engineering - Week 3  \n\n---\n\n# ğŸ™ TeÅŸekkÃ¼rler!\n\nBu proje, makine Ã¶ÄŸrenmesinin temel prensiplerini ve en iyi uygulamalarÄ±nÄ± kapsamlÄ± bir ÅŸekilde gÃ¶sterdi. \n\n**\"In God we trust, all others must bring data.\"** - W. Edwards Deming\n\n---\n---",
      "metadata": {}
    }
  ]
}